

## Diagrama de Arquitetura ‚Äì Fluxo End-to-End

```mermaid
flowchart LR
    %% =====================
    %% PRODUCERS
    %% =====================
    subgraph PROD["Fontes / Producers (.NET em EC2)"]
        P1["Producer .NET<br/>- Extrai c√≥digo<br/>- Define key = c√≥digo<br/>- JSON ~200 bytes"]
    end

    %% =====================
    %% KAFKA / MSK
    %% =====================
    subgraph MSK["Amazon MSK (Kafka)"]
        subgraph T1["T√≥pico mt-c400"]
            P400_0["Parti√ß√£o 0<br/>(c√≥digo 300)"]
            P400_1["Parti√ß√£o 1<br/>(c√≥digo 301)"]
            P400_2["Parti√ß√£o 2<br/>(c√≥digo 302)"]
            P400_3["Parti√ß√£o 3<br/>(c√≥digo 303)"]
            P400_N["Parti√ß√µes extras<br/>(c√≥digos mais quentes)"]
        end

        subgraph T2["T√≥pico mt-c300"]
            P300_0["Parti√ß√£o 0"]
            P300_1["Parti√ß√£o 1"]
        end
    end

    %% =====================
    %% CONSUMERS
    %% =====================
    subgraph CONS["Consumers (.NET em EC2)<br/>Consumer Group"]
        C1["Consumer EC2 #1<br/>Consome 1+ parti√ß√µes"]
        C2["Consumer EC2 #2<br/>Consome 1+ parti√ß√µes"]
        C3["Consumer EC2 #N<br/>Escala horizontal"]
    end

    %% =====================
    %% LAMBDA
    %% =====================
    subgraph AWS["AWS Lambda"]
        L1["Lambda Dispatcher<br/>- Recebe lote<br/>- Roteia para servi√ßos"]
    end

    %% =====================
    %% FLUXOS
    %% =====================
    P1 -->|Produce com key=c√≥digo| MSK

    P400_0 --> C1
    P400_1 --> C2
    P400_2 --> C3
    P400_3 --> C1
    P400_N --> C2

    P300_0 --> C3
    P300_1 --> C1

    C1 -->|Batch JSON| L1
    C2 -->|Batch JSON| L1
    C3 -->|Batch JSON| L1

```
### 1Ô∏è‚É£ Producer (.NET em EC2)

* O Producer **n√£o cria parti√ß√µes dinamicamente**.
* Ele apenas:

  * L√™ a mensagem
  * Extrai o `codigo`
  * Define `key = codigo`
* O Kafka garante que **a mesma key sempre vai para a mesma parti√ß√£o**.

üëâ **Decis√£o importante**:
A l√≥gica de distribui√ß√£o est√° no **Producer**, n√£o no MSK.

---

### 2Ô∏è‚É£ T√≥picos Kafka (Dom√≠nio de Neg√≥cio)

* Cada t√≥pico representa um **dom√≠nio funcional** (`mt-c400`, `mt-c300`).
* N√£o h√° um t√≥pico por c√≥digo ‚Üí evita explos√£o de t√≥picos.
* O t√≥pico mais pesado (`mt-c400`) possui **mais parti√ß√µes**.

üëâ **Argumento forte**:

> ‚ÄúT√≥picos representam dom√≠nios, parti√ß√µes representam escala.‚Äù

---

### 3Ô∏è‚É£ Parti√ß√µes (Escala e Paralelismo)

* Cada parti√ß√£o √©:

  * Unidade de paralelismo
  * Unidade de ordena√ß√£o
* C√≥digos mais frequentes podem:

  * Ter parti√ß√µes dedicadas
  * Ou m√∫ltiplas parti√ß√µes no futuro (sub-key)

üëâ **Trade-off consciente**:
Possibilidade de hot partition, mitig√°vel com monitoramento.

---

### 4Ô∏è‚É£ Consumers em EC2 (.NET)

* Consumers fazem parte de **um √∫nico consumer group**.
* Kafka distribui automaticamente as parti√ß√µes.
* Escalar = subir mais EC2s.
* Cada consumer:

  * Consome mensagens
  * Agrupa em lote
  * Confirma offset ap√≥s sucesso

üëâ **Benef√≠cio**:
Escala horizontal sem mudan√ßa de c√≥digo.

---

### 5Ô∏è‚É£ Lambda (Fan-out e Distribui√ß√£o)

* Recebe mensagens **em lote**.
* Reduz custo de invoca√ß√£o.
* Faz roteamento para servi√ßos downstream.
* Mant√©m consumer simples e r√°pido.

üëâ **Separa√ß√£o clara de responsabilidades**:

* Kafka = throughput
* EC2 = processamento cont√≠nuo
* Lambda = distribui√ß√£o e elasticidade

---

## Mensagem-chave para convencer os pares

> ‚ÄúEssa arquitetura desloca a complexidade para onde temos controle (Producer e Consumer) e mant√©m o MSK simples, est√°vel e escal√°vel. Ela evita explos√£o de t√≥picos, permite crescimento previs√≠vel e √© compat√≠vel com volumes industriais de mensagens.‚Äù

√ìtimo ponto. Como voc√™ est√° desenhando **arquitetura de alto throughput com Kafka + MSK + .NET + Lambda**, existem **conceitos fundamentais (te√≥ricos e pr√°ticos)** que valem muito a pena voc√™ dominar e at√© **defender tecnicamente** em reuni√µes, ADRs ou banca acad√™mica. Vou organizar em **camadas conceituais**, sempre conectando com o seu cen√°rio real (13k msg/s, Pareto 80/20, m√∫ltiplos t√≥picos e parti√ß√µes).

---

## 1. Conceitos fundamentais de Kafka que voc√™ DEVE abordar

### 1.1 T√≥pico ‚â† Fila (log distribu√≠do)

**Conceito**

* Kafka n√£o √© uma fila tradicional, √© um **log distribu√≠do e particionado**.
* Mensagens **n√£o s√£o removidas ao serem consumidas**.
* Cada consumidor mant√©m seu **offset**.

**Por que isso importa no seu caso**

* Voc√™ pode ter **v√°rios consumidores lendo o mesmo t√≥pico** (ex: analytics, auditoria, distribui√ß√£o).
* O Lambda n√£o ‚Äúconsome‚Äù a mensagem, ele **processa uma posi√ß√£o do log**.
* Reprocessamento √© poss√≠vel (reset de offset).

**Frase-chave para defender**

> ‚ÄúKafka desacopla produtores e consumidores usando um log imut√°vel, o que nos d√° replay, escalabilidade e toler√¢ncia a falhas.‚Äù

---

### 1.2 Parti√ß√µes = unidade real de paralelismo

**Conceito**

* A **parti√ß√£o √© a menor unidade de paralelismo** no Kafka.
* Uma parti√ß√£o ‚Üí **1 consumidor por consumer group**.
* N√£o existe paralelismo dentro de uma parti√ß√£o.

**No seu cen√°rio**

* Se voc√™ quer processar **13.000 msg/s**, precisa dividir isso em **fatias paralelas**.
* Exemplo:

  * 13.000 / 13 parti√ß√µes ‚âà 1.000 msg/s por parti√ß√£o
  * 13 consumidores em paralelo

**Decis√£o arquitetural**

* `mt-c400` ‚Üí muitas parti√ß√µes
* `mt-c300` ‚Üí poucas parti√ß√µes

**Frase forte**

> ‚ÄúEscalar Kafka √© escalar parti√ß√µes, n√£o CPU.‚Äù

---

### 1.3 Consumer Group como mecanismo de balanceamento autom√°tico

**Conceito**

* Um **consumer group** garante:

  * Balanceamento autom√°tico de parti√ß√µes
  * Failover transparente
  * Escalabilidade horizontal

**No seu caso**

* Voc√™ sobe mais inst√¢ncias do servi√ßo C#
* Kafka redistribui parti√ß√µes
* Nenhuma configura√ß√£o manual

**Rela√ß√£o direta com Lambda**

* Event Source Mapping do Lambda cria **um consumer group gerenciado pela AWS**

**Frase**

> ‚ÄúConsumer groups nos d√£o elasticidade sem coordena√ß√£o manual.‚Äù

---

## 2. Conceitos de particionamento (onde est√° o ouro)

### 2.1 Hash vs Key-based partitioning

#### Hash / Round-robin

* M√°ximo throughput
* Carga bem distribu√≠da
* Ordem global N√ÉO garantida

#### Key-based (ex: c√≥digo 300, 301‚Ä¶)

* Ordem garantida por chave
* Poss√≠vel hotspot

**No seu cen√°rio**

* 80% das mensagens v√™m de poucos c√≥digos
* Se particionar s√≥ pelo c√≥digo ‚Üí risco de gargalo

**Decis√£o madura**

* Usar **composite key**:

  ```text
  key = codigo + hash(deviceId)
  ```

**Frase t√©cnica**

> ‚ÄúMantemos ordem l√≥gica sem sacrificar paralelismo f√≠sico.‚Äù

---

### 2.2 Hot partitions e Lei de Pareto (80/20)

**Conceito**

* 20% das chaves geram 80% do tr√°fego
* Kafka n√£o resolve hotspot sozinho

**Solu√ß√µes arquiteturais**

1. Mais parti√ß√µes no t√≥pico quente
2. T√≥pico dedicado para heavy hitters
3. Sub-particionamento l√≥gico
4. Sharding por tempo ou regi√£o

**Exemplo**

* `mt-c400-heavy`
* `mt-c400-light`

**Frase**

> ‚ÄúIdentificamos hot keys e tratamos como first-class citizens da arquitetura.‚Äù

---

## 3. Conceitos de throughput e performance

### 3.1 Batching (o conceito mais subestimado)

**Conceito**

* Kafka √© otimizado para **lotes**, n√£o mensagens individuais
* Produzir e consumir em batch aumenta throughput em ordens de magnitude

**No consumidor C#**

* `max.poll.records`
* Processar arrays
* Enviar batches ao Lambda

**Frase**

> ‚ÄúN√≥s otimizamos chamadas, n√£o mensagens.‚Äù

---

### 3.2 Backpressure (fundamental para estabilidade)

**Conceito**

* O sistema **precisa saber desacelerar**
* Sem isso ‚Üí colapso em cascata

**No seu pipeline**

```
Kafka ‚Üí C# ‚Üí Lambda ‚Üí Servi√ßos
```

**Estrat√©gias**

* Pausar consumo (`Pause/Resume`)
* Controlar batch size
* Limitar concorr√™ncia do Lambda
* DLQ para falhas

**Frase**

> ‚ÄúPreferimos atrasar processamento a perder dados.‚Äù

---

## 4. Conceitos de sem√¢ntica de entrega

### 4.1 At-least-once vs At-most-once vs Exactly-once

**Kafka por padr√£o**

* At-least-once

**O que isso significa**

* Mensagens podem ser reprocessadas
* Seu downstream precisa ser **idempotente**

**No Lambda**

* Use:

  * Deduplica√ß√£o
  * Chave de idempot√™ncia
  * DynamoDB conditional writes

**Frase**

> ‚ÄúGarantimos consist√™ncia por design, n√£o por sorte.‚Äù

---

## 5. Kafka + Lambda: choque de modelos

### 5.1 Pull (Kafka) vs Push (Lambda)

**Kafka**

* Pull-based
* Controle de ritmo no consumidor

**Lambda**

* Push-based
* Escala agressivamente

**Conflito**

* Lambda pode escalar mais r√°pido que downstream

**Solu√ß√£o**

* Batch controlado
* Concurrency limit
* Step Functions ou SQS buffer se necess√°rio

**Frase**

> ‚ÄúIntegramos dois modelos opostos controlando o ponto de acoplamento.‚Äù

---

## 6. Conceitos de observabilidade (n√≠vel s√™nior)

### 6.1 Lag como SLO

**Conceito**

* Lag = backlog real
* M√©trica mais importante do Kafka

**Voc√™ deve monitorar**

* Lag por parti√ß√£o
* Throughput por consumer
* Tempo Kafka ‚Üí Lambda

**Frase**

> ‚ÄúLag √© nosso term√¥metro operacional.‚Äù

---

### 6.2 Tracing distribu√≠do

**Conceito**

* Uma mensagem cruza:

  * Kafka
  * C#
  * Lambda
  * Servi√ßos

**Solu√ß√£o**

* Correlation ID
* OpenTelemetry
* Logs estruturados

**Frase**

> ‚ÄúObservabilidade n√£o √© opcional em sistemas distribu√≠dos.‚Äù

---

## 7. Conceitos de arquitetura (para fechar com chave de ouro)

### 7.1 Desacoplamento por eventos

**Voc√™ est√° construindo**

* Uma **arquitetura orientada a eventos**
* N√£o RPC, n√£o request/response

**Benef√≠cios**

* Escalabilidade
* Evolu√ß√£o independente
* Resili√™ncia

---

### 7.2 Design para falha

**Assumir**

* Broker cai
* Consumer cai
* Lambda falha

**Kafka permite**

* Replay
* Reten√ß√£o
* Reprocessamento controlado

**Frase final forte**

> ‚ÄúN√£o evitamos falhas, projetamos para sobreviver a elas.‚Äù

---

## Se quiser ir al√©m (n√≠vel doutorado / staff engineer)

Posso te ajudar a:

* Criar **ADR formal** dessas decis√µes
* Calcular **n√∫mero √≥timo de parti√ß√µes**
* Simular throughput em Python
* Criar um **diagrama C4**
* Escrever isso como **cap√≠tulo de tese ou whitepaper**

Perfeito. Abaixo est√° um **diagrama em Mermaid** focado **exatamente nos pontos de tens√£o da discuss√£o arquitetural**:
isolamento vs compartilhamento, blast radius, prioridade, chave de parti√ß√£o e evolu√ß√£o para arquitetura h√≠brida.

A ideia n√£o √© s√≥ mostrar o ‚Äúfluxo feliz‚Äù, mas **visualizar os riscos e as decis√µes**.

---

## 1Ô∏è‚É£ Vis√£o Geral ‚Äì Arquitetura Atual (Dom√≠nio + Parti√ß√µes)

```mermaid
flowchart LR
    subgraph PROD["Producers (.NET em EC2)"]
        P["Producer<br/>- Extrai c√≥digo<br/>- Define key (ex: c√≥digo)<br/>- JSON 200 bytes"]
    end

    subgraph MSK["Amazon MSK"]
        subgraph C400["T√≥pico mt-c400 (mesmo dom√≠nio)"]
            C400_P0["Parti√ß√£o 0<br/>C√≥digo 300"]
            C400_P1["Parti√ß√£o 1<br/>C√≥digo 301"]
            C400_P2["Parti√ß√£o 2<br/>C√≥digo 302"]
            C400_PN["Parti√ß√µes extras<br/>C√≥digos quentes"]
        end
    end

    subgraph CONS["Consumer Group (.NET EC2)"]
        C1["Consumer #1"]
        C2["Consumer #2"]
        C3["Consumer #N"]
    end

    subgraph LAMBDA["AWS Lambda"]
        L["Lambda Dispatcher<br/>- Batch<br/>- Roteia por c√≥digo"]
    end

    P -->|key = c√≥digo| C400
    C400_P0 --> C1
    C400_P1 --> C2
    C400_P2 --> C3
    C400_PN --> C1

    C1 -->|batch| L
    C2 -->|batch| L
    C3 -->|batch| L
```

### üß† O que este diagrama explica

* **Parti√ß√µes s√£o a unidade de escala**, n√£o t√≥picos
* Ordem √© garantida **por c√≥digo**, n√£o global
* Consumer √© gen√©rico ‚Üí reduz filtering cost
* Lambda isola l√≥gica e fan-out

---

## 2Ô∏è‚É£ Onde mora o risco ‚Äì Blast Radius e Hot Partition

```mermaid
flowchart LR
    subgraph MSK["T√≥pico mt-c400"]
        P0["Parti√ß√£o X<br/>C√≥digo 300<br/>(ALTA PRIORIDADE)"]
        P1["Parti√ß√£o Y<br/>C√≥digo 301<br/>(Volume Alto)"]
    end

    subgraph CONS["Consumer EC2"]
        C["Consumer"]
    end

    P1 -->|Mensagem malformada| C
    C -.->|Erro n√£o tratado| P1
    P1 -.->|Lag aumenta| P0

    style P1 fill:#ffdddd
    style P0 fill:#fff4cc
```

### ‚ö†Ô∏è O que este diagrama evidencia

* Um erro em dados **n√£o cr√≠ticos** pode:

  * Aumentar lag
  * Afetar processamento cr√≠tico
* Esse risco **s√≥ existe** se:

  * Consumer tiver l√≥gica pesada
  * Erro travar parti√ß√£o

üëâ **Mitiga√ß√£o**:

* Consumer simples
* DLQ
* Try/catch por mensagem

---

## 3Ô∏è‚É£ Compara√ß√£o visual ‚Äì Muitos T√≥picos vs Poucos T√≥picos

```mermaid
flowchart TB
    subgraph A["Estrat√©gia A<br/>Muitos T√≥picos"]
        A300["topic-code-300"]
        A301["topic-code-301"]
        A302["topic-code-302"]
    end

    subgraph B["Estrat√©gia B<br/>Dom√≠nio + Parti√ß√µes"]
        B400["mt-c400"]
        B400_P["Parti√ß√µes<br/>300 | 301 | 302"]
    end

    style A fill:#ffe6e6
    style B fill:#e6f2ff
```

### üìä Leitura arquitetural

* Estrat√©gia A:

  * Alto isolamento
  * Alto custo operacional
  * Topic sprawl
* Estrat√©gia B:

  * Bom isolamento l√≥gico
  * Escala eficiente
  * Governan√ßa centralizada

---

## 4Ô∏è‚É£ Evolu√ß√£o Natural ‚Äì Arquitetura H√≠brida (Prioridade)

```mermaid
flowchart LR
    subgraph PROD["Producer (.NET)"]
        P["Producer<br/>Decide t√≥pico<br/>com base na prioridade"]
    end

    subgraph MSK["Amazon MSK"]
        HP["high_priority_events<br/>(C√≥digo 300)"]
        STD["telemetry_standard<br/>(301, 302)"]
    end

    subgraph CONS["Consumers EC2"]
        C_HP["Consumers Alta Prioridade"]
        C_STD["Consumers Standard"]
    end

    subgraph LAMBDA["Lambda"]
        L["Dispatcher"]
    end

    P -->|300| HP
    P -->|301/302| STD

    HP --> C_HP
    STD --> C_STD

    C_HP --> L
    C_STD --> L
```

### üß† Mensagem-chave

* Evolu√ß√£o **n√£o quebra o desenho atual**
* Producer j√° controla:

  * Key
  * T√≥pico
* Isolamento cresce conforme criticidade

---

## 5Ô∏è‚É£ Decis√£o sobre chave ‚Äì `truck_id` vs `codigo`

```mermaid
flowchart LR
    subgraph KEY1["key = truck_id"]
        K1["300 + 301<br/>mesma parti√ß√£o"]
    end

    subgraph KEY2["key = c√≥digo"]
        K2["300 ‚Üí parti√ß√£o A"]
        K3["301 ‚Üí parti√ß√£o B"]
    end

    style KEY1 fill:#ffe6e6
    style KEY2 fill:#e6ffe6
```

### üìå Interpreta√ß√£o

* `truck_id`:

  * Ordem forte
  * Alto acoplamento
* `codigo`:

  * Melhor isolamento
  * Ordem suficiente
  * Menor blast radius

---

## 6Ô∏è‚É£ Diagrama mental para defender a arquitetura

```mermaid
flowchart TB
    A["Dom√≠nio bem definido"] --> B["Poucos t√≥picos"]
    B --> C["Parti√ß√µes para escala"]
    C --> D["Producer controla key"]
    D --> E["Consumer simples"]
    E --> F["Lambda isola fan-out"]
    F --> G["Evolu√ß√£o para isolamento por prioridade"]
```

---

## üéØ Como usar esse material na discuss√£o

Voc√™ pode literalmente apontar para os diagramas e dizer:

* ‚ÄúAqui est√° onde assumimos risco conscientemente‚Äù
* ‚ÄúAqui est√° como mitigamos‚Äù
* ‚ÄúAqui est√° como evolu√≠mos sem reescrever tudo‚Äù


*** 

# Abordagem do producer 

1. Objetivo da POC
2. Responsabilidades do Producer
3. Arquitetura l√≥gica do Producer
4. Estrat√©gia para t√≥picos e parti√ß√µes
5. Escala: 1 inst√¢ncia vs m√∫ltiplas inst√¢ncias
6. Controle, observabilidade e governan√ßa
7. Fluxograma (Mermaid)
8. Etapas de implementa√ß√£o
9. Pontos perigosos e riscos reais

---

# üéØ 1. Objetivo da POC (Producer)

### O que a POC PRECISA provar

A POC do **Producer EC2 .NET** deve responder objetivamente:

* Consigo **publicar corretamente** em m√∫ltiplos t√≥picos?
* Consigo **controlar a distribui√ß√£o de mensagens por parti√ß√£o**?
* Consigo **simular volume realista**?
* Consigo **escalar horizontalmente sem quebrar nada**?
* Consigo **medir impacto em lat√™ncia e custo**?

‚ö†Ô∏è **Importante**:
A POC **n√£o** precisa:

* Ser altamente resiliente
* Ter autoscaling perfeito
* Ter HA completo

Ela precisa **validar decis√µes arquiteturais**, n√£o ser produ√ß√£o.

---

# üß± 2. Responsabilidades do Producer

O Producer **n√£o √© burro**, mas tamb√©m **n√£o deve ser inteligente demais**.

### Responsabilidades corretas

‚úî Escolher o t√≥pico
‚úî Definir a key de parti√ß√£o
‚úî Garantir confiabilidade (`acks=all`)
‚úî Controlar taxa (throttling)
‚úî Emitir m√©tricas

### Responsabilidades que N√ÉO s√£o dele

‚ùå Saber quantas parti√ß√µes existem
‚ùå Fazer load balancing manual
‚ùå Garantir ordem global
‚ùå Saber quem vai consumir

üëâ **Kafka j√° faz isso melhor.**

---

# üß† 3. Arquitetura l√≥gica do Producer

Pense no Producer como **pipeline**, n√£o como um ‚Äúservi√ßo REST‚Äù.

```
Input Generator
     ‚Üì
Message Builder
     ‚Üì
Topic Resolver
     ‚Üì
Partition Key Resolver
     ‚Üì
Kafka Producer
     ‚Üì
Metrics & Logs
```

---

# üß© 4. Estrat√©gia para t√≥picos e parti√ß√µes

## üîë Regra de ouro

> **Producer escolhe a KEY, Kafka escolhe a PARTI√á√ÉO**

### Exemplo

```text
Topic: mt-c400
Key: hash(codigo + truck_id)
```

Kafka:

* Aplica hash(key)
* Mod N (parti√ß√µes)
* Distribui automaticamente

‚ö†Ô∏è Voc√™ **n√£o** deve usar `partition=X` manualmente na POC.

---

## üîç Estrat√©gia de chave (decis√£o cr√≠tica)

### Op√ß√µes

| Estrat√©gia           | Pr√≥s               | Contras        |
| -------------------- | ------------------ | -------------- |
| `truck_id`           | Ordem por caminh√£o | Hot partitions |
| `codigo`             | Isolamento l√≥gico  | Perda de ordem |
| `hash(codigo+truck)` | Equil√≠brio         | Ordem parcial  |

üëâ **Para POC:**
Use `hash(codigo + truck_id)`
√â a mais defens√°vel.

---

# ‚öñÔ∏è 5. Escala: quantas inst√¢ncias de Producer?

### ‚ùó Verdade importante

> **Kafka Producer escala melhor por THREAD do que por INST√ÇNCIA**

### Estrat√©gia correta para POC

#### Fase 1 ‚Äì 1 EC2

* 1 processo
* 1 Producer
* 5‚Äì10 threads
* Controle de TPS

#### Fase 2 ‚Äì 2 EC2

* Mesma config
* Mesmos t√≥picos
* Mesmas chaves

üëâ Kafka garante que:

* N√£o h√° duplica√ß√£o
* N√£o h√° conflito
* N√£o h√° desordem por key

---

## ‚ö†Ô∏è Erro comum

> ‚ÄúVou criar um Producer por parti√ß√£o‚Äù

‚ùå ERRADO
Isso quebra:

* Escala
* Rebalance
* Custo

---

# üéõÔ∏è 6. Controle e governan√ßa

### Controle de taxa (obrigat√≥rio)

```text
- Mensagens/segundo
- Bytes/segundo
```

Implemente:

* Token bucket simples
* Sleep controlado
* Config via ENV VAR

---

### Observabilidade m√≠nima

| M√©trica     | Por qu√™        |
| ----------- | -------------- |
| msg/s       | Throughput     |
| ack latency | Sa√∫de MSK      |
| error rate  | Confiabilidade |
| retries     | Satura√ß√£o      |

---

# üîÅ 7. Fluxograma do Producer (Mermaid)

```mermaid
flowchart TD
    A[Start Producer] --> B[Load Config]
    B --> C[Initialize Kafka Producer]
    C --> D[Start Worker Threads]

    D --> E[Generate Payload]
    E --> F[Resolve Topic]
    F --> G[Resolve Key]
    G --> H[Send to Kafka]

    H --> I{Ack OK?}
    I -->|Yes| J[Emit Metrics]
    I -->|No| K[Retry / Log Error]

    J --> E
```

---

# üõ†Ô∏è 8. Etapas pr√°ticas da POC

## Etapa 1 ‚Äì Infra m√≠nima

* EC2 t3.medium
* Security Group liberando MSK
* Certificados funcionando

---

## Etapa 2 ‚Äì C√≥digo Producer .NET

Componentes:

* `ProducerFactory`
* `MessageGenerator`
* `TopicRouter`
* `KeyResolver`
* `MetricsEmitter`

---

## Etapa 3 ‚Äì Simula√ß√£o de carga

* Ramp-up gradual
* 1 ‚Üí 5 ‚Üí 10 threads
* Observa lat√™ncia

---

## Etapa 4 ‚Äì Scale-out

* Sobe segunda EC2
* Mesmo c√≥digo
* Observa:

  * Distribui√ß√£o
  * Throughput
  * Impacto no MSK

---

# ‚ò†Ô∏è 9. Pontos perigosos e riscos reais

## üî• Risco 1 ‚Äì Hot partitions

* Chave mal escolhida
* Solu√ß√£o: hash composta

---

## üî• Risco 2 ‚Äì Buffer interno do Producer

* `queue.buffering.max.messages`
* Pode causar OOM
* Monitorar

---

## üî• Risco 3 ‚Äì Backpressure invis√≠vel

* MSK lento
* Producer continua aceitando
* Lat√™ncia explode

---

## üî• Risco 4 ‚Äì Overengineering

* Producer ‚Äúinteligente demais‚Äù
* L√≥gica duplicada
* Dif√≠cil de manter

---

## üî• Risco 5 ‚Äì Falta de m√©tricas

> ‚ÄúSem m√©tricas, voc√™ n√£o tem arquitetura, s√≥ esperan√ßa.‚Äù

---

# üß† Conclus√£o arquitetural

> O Producer **n√£o controla o Kafka**.
> Ele **declara inten√ß√£o** (key, t√≥pico, confiabilidade).
> O Kafka **executa a estrat√©gia de escala**.

Essa POC vai te permitir:

* Defender a arquitetura com n√∫meros
* Antecipar gargalos
* Calibrar decis√µes antes da produ√ß√£o

---

## üîú Pr√≥ximo passo (se quiser)

Posso:

* Criar **pseudoc√≥digo .NET detalhado do Producer**
* Criar **checklist de POC**
* Criar **template de relat√≥rio de resultados**
* Avan√ßar para **EC2 Consumer**

Se quiser, diga:
üëâ *‚ÄúVamos detalhar o c√≥digo do Producer‚Äù*

Perfeito. Vou te entregar **dois diagramas complementares**, no n√≠vel que normalmente aparece em **documenta√ß√£o de arquitetura s√©ria**:

1. **Diagrama arquitetural do Producer (vis√£o estrutural)**
2. **Fluxograma detalhado de execu√ß√£o do Producer (vis√£o comportamental)**

Ambos pensados para:

* Sustentar discuss√£o com arquitetos, SRE e FinOps
* Ajudar algu√©m a **construir o servi√ßo do zero**
* Deixar expl√≠cito **onde est√£o os riscos e controles**

---

# üß± 1Ô∏è‚É£ Diagrama Arquitetural do Servi√ßo Producer (.NET em EC2)

üëâ **Pergunta que esse diagrama responde**

> ‚ÄúQue componentes existem dentro do Producer e como eles se relacionam?‚Äù

```mermaid
flowchart LR
    subgraph EC2["EC2 Producer (.NET)"]
        CFG["Config Loader<br/>(ENV / AppSettings)"]
        GEN["Message Generator<br/>(Simula fontes)"]
        ROUTER["Topic Router<br/>(Regra por c√≥digo)"]
        KEY["Key Resolver<br/>(hash(codigo+truck))"]
        KPROD["Kafka Producer<br/>(librdkafka)"]
        MET["Metrics & Logs<br/>(CloudWatch / OTEL)"]
        RATE["Rate Limiter<br/>(TPS / Bytes)"]
    end

    subgraph MSK["Amazon MSK"]
        T400["Topic mt-c400<br/>(N Parti√ß√µes)"]
        T300["Topic mt-c300<br/>(M Parti√ß√µes)"]
    end

    CFG --> GEN
    GEN --> ROUTER
    ROUTER --> KEY
    KEY --> RATE
    RATE --> KPROD
    KPROD --> T400
    KPROD --> T300
    KPROD --> MET
    RATE --> MET
```

---

## üìå Como explicar esse diagrama em reuni√£o

* **Config Loader**
  ‚Üí Nada hardcoded. TPS, t√≥picos e comportamento s√£o configur√°veis.

* **Message Generator**
  ‚Üí Simula m√∫ltiplas fontes e Pareto (80/20).

* **Topic Router**
  ‚Üí Decide *qual dom√≠nio* (mt-c400, mt-c300).

* **Key Resolver**
  ‚Üí Define *como Kafka ir√° distribuir*.

* **Rate Limiter**
  ‚Üí Protege o MSK **e o pr√≥prio Producer**.

* **Kafka Producer**
  ‚Üí √önico ponto de comunica√ß√£o com o cluster.

* **Metrics**
  ‚Üí Sem isso, a POC n√£o vale nada.

---

# üîÅ 2Ô∏è‚É£ Fluxograma Detalhado do Producer (Execu√ß√£o passo a passo)

üëâ **Pergunta que esse fluxograma responde**

> ‚ÄúO que acontece exatamente desde o start at√© o envio cont√≠nuo?‚Äù

```mermaid
flowchart TD
    A[Start EC2 Producer] --> B[Load Configurations]
    B --> C[Validate Configs]
    C -->|Invalid| CERR[Fail Fast & Exit]
    C -->|Valid| D[Init Kafka Producer]

    D --> E[Init Metrics & Logs]
    E --> F[Start Worker Threads]

    F --> G[Generate Message]
    G --> H[Extract Business Code]
    H --> I[Resolve Topic]
    I --> J[Resolve Partition Key]

    J --> K[Rate Limit Check]
    K -->|Exceeded| KWAIT[Wait / Sleep]
    KWAIT --> K
    K -->|Allowed| L[Produce Message]

    L --> M{Ack Received?}
    M -->|Yes| N[Update Metrics]
    M -->|No| O[Retry Policy]

    O -->|Retryable| L
    O -->|Fatal| P[Log Error & Continue]

    N --> G
```

---

## üìå Pontos cr√≠ticos destacados no fluxograma

### üî¥ Fail Fast

* Se config errada ‚Üí **n√£o sobe**
* Evita producer ‚Äúzumbi‚Äù

---

### üî¥ Rate Limiter antes do Kafka

* Kafka **n√£o protege voc√™**
* Sem isso:

  * Mem√≥ria cresce
  * Lat√™ncia explode
  * EC2 morre

---

### üî¥ Retry consciente

* Nem todo erro √© retry√°vel
* Erro de schema ‚â† erro de rede

---

# ‚ö†Ô∏è Pontos perigosos expl√≠citos no diagrama

| Ponto             | Risco              | Mitiga√ß√£o         |
| ----------------- | ------------------ | ----------------- |
| Key mal escolhida | Hot partition      | Hash composta     |
| Sem rate limit    | OOM                | Throttling        |
| Retries infinitos | Loop infinito      | Retry com limite  |
| Config fixa       | Imposs√≠vel escalar | ENV vars          |
| M√©tricas pobres   | Arquitetura ‚Äúcega‚Äù | CloudWatch / OTEL |

---

# üß† Como um arquiteto s√™nior justificaria esse desenho

> ‚ÄúEsse Producer n√£o sabe nada sobre o MSK al√©m do necess√°rio. Ele declara inten√ß√£o (t√≥pico, chave, confiabilidade) e deixa o Kafka fazer o trabalho pesado. Isso reduz acoplamento, facilita escala e torna o comportamento previs√≠vel sob carga.‚Äù

---

# üìã Checklist r√°pido (para POC)

‚úî C√≥digo configur√°vel
‚úî Simula√ß√£o Pareto
‚úî M√©tricas claras
‚úî Rate limit ativo
‚úî Chave bem definida
‚úî F√°cil de escalar horizontalmente

Perfeito. Abaixo est√° um **PLAYBOOK DE AUMENTO DE PARTI√á√ïES KAFKA (MSK)**, escrito no n√≠vel que **SRE, arquiteto e time .NET** esperam ver.
Ele cobre **quando fazer**, **impactos reais**, **o que esperar**, **como mitigar**, e **como o c√≥digo .NET deve se comportar antes e depois**.

Este material √© **diretamente reutiliz√°vel** na sua documenta√ß√£o oficial.

---

# üìò PLAYBOOK ‚Äì Aumento de Parti√ß√µes em Kafka (MSK)

## üéØ Objetivo

Permitir **aumento de throughput e paralelismo** sem downtime, mantendo:

* previsibilidade operacional
* impacto controlado
* zero mudan√ßa no c√≥digo do Producer/Consumer (.NET)

---

## 1Ô∏è‚É£ Quando aumentar parti√ß√µes (crit√©rios objetivos)

Voc√™ **N√ÉO aumenta parti√ß√µes por intui√ß√£o**.
Voc√™ aumenta quando **m√©tricas indicam gargalo estrutural**.

### Indicadores claros

| M√©trica                            | Sintoma                 |
| ---------------------------------- | ----------------------- |
| Consumer Lag cresce continuamente  | Capacidade insuficiente |
| Apenas algumas parti√ß√µes saturadas | Hot partition           |
| CPU de consumers < 50%             | Falta paralelismo       |
| Throughput estagnado               | Limite f√≠sico           |
| Escalar consumers n√£o ajuda        | Falta parti√ß√µes         |

üëâ **Regra pr√°tica**

> N√∫mero de parti√ß√µes ‚â• n√∫mero m√°ximo esperado de consumers ativos

---

## 2Ô∏è‚É£ O que acontece tecnicamente ao aumentar parti√ß√µes

### Estado ANTES

```
Topic mt-c400
Parti√ß√µes: 8
partition = hash(key) % 8
```

### Estado DEPOIS

```
Topic mt-c400
Parti√ß√µes: 16
partition = hash(key) % 16
```

### Efeitos imediatos

‚úî Mensagens antigas permanecem onde est√£o
‚úî Mensagens novas passam a usar novas parti√ß√µes
‚ö† A mesma key pode ir para outra parti√ß√£o
‚ö† Ordem hist√≥rica entre mensagens antigas e novas √© quebrada

üëâ **Nada √© perdido. Nada √© duplicado.**

---

## 3Ô∏è‚É£ Impactos esperados (e normais)

### 3.1 Rebalance do Consumer Group

**O que acontece**

* Todos os consumers pausam
* Kafka redistribui parti√ß√µes
* Consumo retoma

**O que esperar**

* Pausa de segundos (ou minutos se exagerou nas parti√ß√µes)
* Lag tempor√°rio

**Mitiga√ß√£o**

* Aumentar parti√ß√µes fora do hor√°rio de pico
* Garantir que consumers sejam idempotentes

---

### 3.2 Redistribui√ß√£o de carga

**Antes**

```
Parti√ß√£o 2 ‚Üí 80% do tr√°fego
```

**Depois**

```
Parti√ß√£o 2 ‚Üí 40%
Parti√ß√£o 10 ‚Üí 40%
```

üëâ **Esse √© o ganho esperado.**

---

### 3.3 Mudan√ßa invis√≠vel para o Producer

‚úî Producer n√£o sabe
‚úî Producer n√£o muda
‚úî Producer continua saud√°vel

**SE** voc√™ usou:

* key-based partitioning
* sem parti√ß√£o fixa no c√≥digo

---

## 4Ô∏è‚É£ Riscos reais e como resolver

### üî• RISCO 1 ‚Äì Explos√£o de rebalance

**Causa**

* Muitas parti√ß√µes
* Muitos consumers
* Deploy frequente

**Mitiga√ß√£o**

* Evitar ‚Äúparti√ß√µes demais‚Äù
* Preferir scale-up antes de scale-out
* Evitar restart em massa

---

### üî• RISCO 2 ‚Äì Quebra de expectativa de ordem

**Causa**

* Key vai para outra parti√ß√£o

**Mitiga√ß√£o**

* Documentar claramente:

  > ‚ÄúOrdem √© garantida apenas ap√≥s o resize‚Äù
* Usar timestamp de evento

---

### üî• RISCO 3 ‚Äì Hot partition continua

**Causa**

* Chave mal escolhida

**Mitiga√ß√£o**

```text
ANTES: key = codigo
DEPOIS: key = hash(codigo + truck_id)
```

---

## 5Ô∏è‚É£ Como se preparar ANTES do aumento (obrigat√≥rio)

### ‚úî 1. C√≥digo .NET deve ser agn√≥stico a parti√ß√µes

‚ùå ERRADO

```csharp
new TopicPartition("mt-c400", new Partition(3))
```

‚úî CORRETO

```csharp
producer.Produce(
    "mt-c400",
    new Message<string, string>
    {
        Key = $"{codigo}:{truckId}",
        Value = payload
    }
);
```

---

### ‚úî 2. Consumers devem ser idempotentes

Ap√≥s rebalance:

* Mensagem pode ser reprocessada
* Offset pode ser replayado

üëâ Lambda downstream deve suportar isso.

---

### ‚úî 3. M√©tricas obrigat√≥rias antes do resize

* Consumer lag por parti√ß√£o
* Rebalance time
* Throughput por key
* Ack latency do Producer

---

## 6Ô∏è‚É£ Passo a passo operacional (Playbook)

### üîπ PASSO 1 ‚Äì Validar necessidade

* Confirmar gargalo
* Confirmar que mais consumers n√£o resolvem

---

### üîπ PASSO 2 ‚Äì Escolher novo n√∫mero

Regra pr√°tica:

```
Novo N = 2x parti√ß√µes atuais
```

Evite:

* Incrementos pequenos
* Ajustes frequentes

---

### üîπ PASSO 3 ‚Äì Executar resize

```bash
kafka-topics.sh \
  --bootstrap-server <broker> \
  --alter \
  --topic mt-c400 \
  --partitions 16
```

‚úî Sem downtime
‚úî Sem restart

---

### üîπ PASSO 4 ‚Äì Monitorar rebalance

Acompanhar:

* consumer-group-state
* lag total
* throughput

---

### üîπ PASSO 5 ‚Äì Validar estabiliza√ß√£o

Crit√©rio de sucesso:

* Lag volta ao normal
* CPU de consumers sobe
* Throughput aumenta

---

## 7Ô∏è‚É£ O que N√ÉO fazer (anti-patterns)

‚ùå Fixar parti√ß√µes no Producer
‚ùå Criar l√≥gica ‚Äúparti√ß√£o dedicada‚Äù no c√≥digo
‚ùå Aumentar parti√ß√µes toda semana
‚ùå Ignorar rebalance
‚ùå Achar que aumento √© ‚Äúsem impacto‚Äù

---

## 8Ô∏è‚É£ Pergunta dura de SRE (simula√ß√£o)

### ‚ùì ‚ÄúSe dobrarmos as parti√ß√µes agora, o que pode dar errado?‚Äù

**Resposta correta**

> ‚ÄúTeremos um rebalance tempor√°rio e poss√≠vel quebra de ordem hist√≥rica, mas nenhum impacto em integridade, perda de dados ou necessidade de mudan√ßa de c√≥digo.‚Äù

---

## 9Ô∏è‚É£ Pergunta dura de arquiteto (simula√ß√£o)

### ‚ùì ‚ÄúPor que n√£o criar outro t√≥pico em vez de aumentar parti√ß√µes?‚Äù

**Resposta madura**

> ‚ÄúPorque o dom√≠nio n√£o mudou. S√≥ a capacidade. Parti√ß√µes escalam processamento, t√≥picos escalam contratos.‚Äù

---

## üîö Conclus√£o para documenta√ß√£o

> ‚ÄúAumentar parti√ß√µes √© uma opera√ß√£o planejada, previs√≠vel e segura quando o Producer √© key-based, os Consumers s√£o idempotentes e o impacto √© monitorado. O risco n√£o est√° no Kafka, est√° em arquiteturas que acoplam c√≥digo √† topologia.‚Äù

Perfeito. Vou estruturar **um playbook completo para o CONSUMER (.NET em EC2)**, j√° alinhado com tudo o que discutimos: MSK gerenciado, m√∫ltiplos t√≥picos, m√∫ltiplas parti√ß√µes, possibilidade de aumento de parti√ß√µes no futuro, batching e integra√ß√£o com Lambda.

Vou escrever isso no **n√≠vel de documenta√ß√£o t√©cnica + operacional**, do jeito que um **SRE, arquiteto ou tech lead espera ler**.

---

# üìò Playbook do Consumer Kafka (.NET + EC2 + MSK)

## 1. Papel do Consumer na Arquitetura

O **consumer** √© o componente mais cr√≠tico da arquitetura porque ele:

* Converte **throughput Kafka ‚Üí processamento real**
* Define **lat√™ncia**, **ordena√ß√£o**, **paralelismo**
* √â o ponto onde **backpressure aparece**
* √â onde falhas viram **reprocessamento, duplica√ß√£o ou perda**

Na sua arquitetura, o consumer:

* Consome t√≥picos como `mt-c400`
* L√™ **N parti√ß√µes em paralelo**
* Agrega mensagens em **lotes**
* Dispara **Lambda** quando:

  * Batch size atingido **OU**
  * Timeout atingido

---

## 2. Princ√≠pios de Design (n√£o negoci√°veis)

### 2.1 Consumer Group √© obrigat√≥rio

> **Escalabilidade em Kafka = consumer group**

* Cada inst√¢ncia EC2 do consumer:

  * Usa o **mesmo `group.id`**
* Kafka garante:

  * **1 parti√ß√£o ‚Üí 1 consumer ativo**
  * Rebalance autom√°tico

üëâ Se voc√™ tem **12 parti√ß√µes**, o m√°ximo de paralelismo real √© **12 consumers ativos**.

---

### 2.2 Consumer N√ÉO decide parti√ß√£o

> Diferente do producer, o consumer **n√£o escolhe parti√ß√µes**

Ele:

* Recebe parti√ß√µes atribu√≠das pelo **Kafka Group Coordinator**
* Deve ser **agn√≥stico** √† quantidade de parti√ß√µes

Isso √© essencial para:

* Suportar **aumento futuro de parti√ß√µes**
* Evitar reescrita do c√≥digo

---

## 3. Estrat√©gia de Escala do Consumer

### 3.1 Rela√ß√£o Parti√ß√µes x Inst√¢ncias

| Parti√ß√µes | EC2 Consumers | Resultado                    |
| --------- | ------------- | ---------------------------- |
| 6         | 3             | Cada EC2 consome 2 parti√ß√µes |
| 6         | 6             | 1 parti√ß√£o por EC2           |
| 6         | 10            | 4 EC2 ficam ociosos          |
| 12        | 6             | Cada EC2 consome 2 parti√ß√µes |

üëâ **Nunca escale EC2 sem considerar parti√ß√µes**
üëâ Escalar al√©m do n√∫mero de parti√ß√µes **n√£o aumenta throughput**

---

### 3.2 Modelo recomendado

* **Auto Scaling Group (ASG)**
* M√©tricas:

  * Lag por consumer group
  * CPU / mem√≥ria
* Escala:

  * Scale out **at√© o limite de parti√ß√µes**
  * Depois disso ‚Üí s√≥ aumenta custo

---

## 4. Fluxo L√≥gico do Consumer

### 4.1 Fluxo macro

1. EC2 sobe
2. Inicializa Kafka Consumer
3. Entra no Consumer Group
4. Kafka atribui parti√ß√µes
5. Loop de consumo:

   * Poll mensagens
   * Bufferiza
   * Dispara Lambda
   * Commita offsets

---

### 4.2 Fluxograma (mental)

```
START
 ‚Üì
Connect to MSK (mTLS)
 ‚Üì
Join Consumer Group
 ‚Üì
Get Assigned Partitions
 ‚Üì
WHILE running:
    Poll messages
    Add to batch
    IF batch size OR timeout:
        Call Lambda
        Commit offsets
```

---

## 5. Estrat√©gia de Batching (fundamental)

### 5.1 Por que batching?

Sem batching:

* Milhares de invoca√ß√µes Lambda
* Custo alto
* Lat√™ncia vari√°vel

Com batching:

* Controle de custo
* Throughput previs√≠vel
* Melhor uso de rede

---

### 5.2 Tipos de batching

Voc√™ **DEVE** usar dois gatilhos:

1. **Batch Size**

   * Ex: 500 mensagens
2. **Batch Timeout**

   * Ex: 1 segundo

> Nunca use apenas tamanho ‚Äî isso causa lat√™ncia infinita em per√≠odos de baixo tr√°fego

---

## 6. Commit de Offset (ponto cr√≠tico)

### 6.1 Estrat√©gia correta

* `EnableAutoCommit = false`
* Commit **ap√≥s Lambda responder OK**

```csharp
consumer.Commit();
```

---

### 6.2 Riscos

| Situa√ß√£o                | Impacto             |
| ----------------------- | ------------------- |
| Commit antes do Lambda  | Perda de dados      |
| Commit depois do Lambda | Poss√≠vel duplica√ß√£o |
| Lambda falha            | Reprocessamento     |

üëâ **Kafka trabalha com ‚Äúat-least-once‚Äù**
üëâ Duplica√ß√£o √© aceit√°vel, perda n√£o

---

## 7. Integra√ß√£o com Lambda

### 7.1 Modelo recomendado

* Consumer chama Lambda **sincronamente**
* Payload cont√©m:

  * Lista de mensagens
  * Metadados (topic, partition, offset)

```json
{
  "topic": "mt-c400",
  "partition": 3,
  "messages": [...]
}
```

---

### 7.2 Por que n√£o ass√≠ncrono?

* Voc√™ perde controle de sucesso/falha
* N√£o sabe quando commitar offsets
* Quebra consist√™ncia

---

## 8. Impacto do Aumento de Parti√ß√µes no Consumer

### 8.1 O que acontece tecnicamente?

Quando voc√™ aumenta parti√ß√µes:

1. Kafka dispara **rebalance**
2. Consumers pausam
3. Parti√ß√µes s√£o redistribu√≠das
4. Consumo continua

---

### 8.2 Impactos pr√°ticos

| Impacto    | Explica√ß√£o              |
| ---------- | ----------------------- |
| Rebalance  | Pausa tempor√°ria        |
| Ordem      | Ordem global quebra     |
| Throughput | Aumenta potencial       |
| C√≥digo     | N√£o muda (se bem feito) |

üëâ **Consumer bem feito n√£o precisa mudar uma linha**

---

## 9. Pontos de Aten√ß√£o (riscos reais)

### 9.1 Rebalance frequente

Causas:

* Muitas inst√¢ncias subindo/descendo
* Timeout mal configurado

Mitiga√ß√£o:

* Ajustar:

  * `session.timeout.ms`
  * `max.poll.interval.ms`

---

### 9.2 Backpressure

Se Lambda ficar lenta:

* Batch cresce
* Lag aumenta
* ASG tenta escalar

Mitiga√ß√£o:

* Timeout de Lambda
* Circuit breaker
* Limite de batch

---

### 9.3 Lag invis√≠vel

Se voc√™ n√£o monitora:

* O sistema ‚Äúparece vivo‚Äù
* Mas est√° horas atrasado

Obrigat√≥rio:

* Monitorar **Consumer Group Lag**

---

## 10. Perguntas duras que v√£o surgir (e respostas)

### ‚ùì ‚ÄúE se dobrar o volume em 6 meses?‚Äù

‚úîÔ∏è Resposta:

> Aumentamos parti√ß√µes, o consumer absorve automaticamente via rebalance. O c√≥digo j√° est√° preparado.

---

### ‚ùì ‚ÄúE se uma EC2 cair?‚Äù

‚úîÔ∏è Resposta:

> Kafka redistribui parti√ß√µes para os outros consumers automaticamente.

---

### ‚ùì ‚ÄúPor que n√£o Lambda direto consumindo Kafka?‚Äù

‚úîÔ∏è Resposta:

> Lambda n√£o √© ideal para:

* Long-lived connections
* Alto throughput cont√≠nuo
* Controle fino de offset

---

## 11. Checklist de POC ‚Äì Consumer

### C√≥digo

* [ ] Consumer Group configurado
* [ ] Commit manual
* [ ] Batch size + timeout
* [ ] Logs estruturados

### Infra

* [ ] ASG configurado
* [ ] IAM para Lambda invoke
* [ ] Certificados mTLS

### Observabilidade

* [ ] Lag por consumer group
* [ ] Tempo de batch
* [ ] Erros de Lambda

---

## 12. Conclus√£o (frase de arquiteto)

> **O consumer √© o elemento que transforma paralelismo do Kafka em capacidade real de processamento.**
> Se ele for stateless, idempotente e orientado a consumer groups, a arquitetura escala horizontalmente sem reescrita, mesmo com aumento de parti√ß√µes ao longo do tempo.

---

Perfeito. Abaixo est√° **um diagrama Mermaid focado exclusivamente no CONSUMER (.NET em EC2)**, cobrindo:

* Consumer Group
* Atribui√ß√£o de parti√ß√µes
* Batching
* Commit de offset
* Chamada ao Lambda
* Rebalance
* Observabilidade

Voc√™ pode colar isso **diretamente no draw.io (diagrams.net)** ou em qualquer editor que suporte Mermaid.

---

## üìä Diagrama Mermaid ‚Äî Consumer Kafka (.NET + EC2)

```mermaid
flowchart TD
    subgraph MSK["Amazon MSK (Kafka Cluster)"]
        T1["T√≥pico: mt-c400"]
        P0["Parti√ß√£o 0"]
        P1["Parti√ß√£o 1"]
        P2["Parti√ß√£o 2"]
        Pn["Parti√ß√£o N"]

        T1 --> P0
        T1 --> P1
        T1 --> P2
        T1 --> Pn
    end

    subgraph CG["Consumer Group: mt-c400-consumer-group"]
        C1["EC2 Consumer #1 (.NET)"]
        C2["EC2 Consumer #2 (.NET)"]
        C3["EC2 Consumer #3 (.NET)"]
    end

    P0 -->|Assign| C1
    P1 -->|Assign| C2
    P2 -->|Assign| C3
    Pn -->|Assign| C1

    subgraph C1_FLOW["Fluxo Interno do Consumer"]
        POLL["Poll() Kafka"]
        BUFFER["Buffer de Mensagens"]
        CHECK{"Batch Size<br/>ou Timeout?"}
        INVOKE["Invoke Lambda<br/>(Sync)"]
        COMMIT["Commit Offset"]
    end

    C1 --> POLL
    POLL --> BUFFER
    BUFFER --> CHECK
    CHECK -- N√£o --> POLL
    CHECK -- Sim --> INVOKE
    INVOKE -->|OK| COMMIT
    COMMIT --> POLL

    INVOKE -->|Erro| DLQ["Retry / DLQ / Backoff"]

    subgraph OBS["Observabilidade"]
        LAG["Consumer Group Lag"]
        METRICS["CPU / Mem√≥ria"]
        LOGS["Logs Estruturados"]
    end

    C1 --> LAG
    C2 --> LAG
    C3 --> LAG

    C1 --> METRICS
    C2 --> METRICS
    C3 --> METRICS

    C1 --> LOGS
    C2 --> LOGS
    C3 --> LOGS

    subgraph REBALANCE["Evento de Rebalance"]
        SCALE["Scale Out / In EC2"]
        REDIST["Redistribui√ß√£o de Parti√ß√µes"]
    end

    SCALE --> REDIST
    REDIST --> C1
    REDIST --> C2
    REDIST --> C3
```

---

## üß† Como interpretar esse diagrama (para explicar aos pares)

### 1Ô∏è‚É£ MSK e Parti√ß√µes

* O t√≥pico `mt-c400` √© dividido em **N parti√ß√µes**
* Kafka garante **ordem por parti√ß√£o**

---

### 2Ô∏è‚É£ Consumer Group

* Todas as EC2 usam o **mesmo group.id**
* Kafka atribui parti√ß√µes dinamicamente
* **1 parti√ß√£o ‚Üí 1 consumer ativo**

---

### 3Ô∏è‚É£ Fluxo interno do Consumer

* `Poll()` l√™ mensagens
* Mensagens v√£o para buffer
* Quando:

  * Batch size **OU**
  * Timeout
    ‚Üí Lambda √© invocado

---

### 4Ô∏è‚É£ Commit de Offset

* S√≥ ocorre **ap√≥s Lambda responder OK**
* Garante **at-least-once**

---

### 5Ô∏è‚É£ Rebalance

* Acontece quando:

  * Nova EC2 sobe
  * EC2 cai
  * Parti√ß√µes aumentam
* Kafka redistribui automaticamente

---

### 6Ô∏è‚É£ Observabilidade

* **Lag** √© o principal KPI
* CPU/Mem√≥ria mostram satura√ß√£o
* Logs ajudam a diagnosticar rebalance e falhas

---

## üéØ Mensagem-chave para a documenta√ß√£o

> O consumer √© stateless, orientado a consumer group e desacoplado do n√∫mero de parti√ß√µes.
> Isso permite escalar horizontalmente, absorver aumento de parti√ß√µes e manter confiabilidade sem mudan√ßas de c√≥digo.

Excelente pedido ‚Äî **Consumer Group √© o cora√ß√£o da sua arquitetura** e normalmente √© onde arquitetos, SREs e seniors mais questionam.
Vou fazer em **tr√™s n√≠veis**:

1. **Explica√ß√£o conceitual profunda (o ‚Äúporqu√™‚Äù)**
2. **Como isso se traduz na sua aplica√ß√£o .NET em EC2**
3. **Diagrama Mermaid did√°tico para documenta√ß√£o e apresenta√ß√£o**

---

# 1Ô∏è‚É£ O que √© um Consumer Group (conceito profundo)

Um **Consumer Group** no Kafka √© um **mecanismo de coordena√ß√£o distribu√≠da** que resolve **tr√™s problemas fundamentais**:

---

## üîπ Problema 1 ‚Äì Escalabilidade horizontal

Sem consumer group:

* Um consumer l√™ tudo
* Limite f√≠sico de CPU / rede

Com consumer group:

* V√°rias inst√¢ncias leem **em paralelo**
* Kafka distribui as **parti√ß√µes** entre elas

> üìå **Regra de ouro**
>
> * 1 parti√ß√£o ‚Üí **somente 1 consumer ativo**
> * 1 consumer ‚Üí **pode ler v√°rias parti√ß√µes**

---

## üîπ Problema 2 ‚Äì Garantia de ordem

Kafka **n√£o garante ordem global**, apenas:

> **Ordem dentro da mesma parti√ß√£o**

O consumer group **preserva essa garantia**, porque:

* Uma parti√ß√£o nunca √© processada por dois consumers ao mesmo tempo
* Logo, a sequ√™ncia de mensagens √© mantida

---

## üîπ Problema 3 ‚Äì Toler√¢ncia a falhas

Se um consumer cai:

* Kafka detecta falha via **heartbeat**
* Redistribui as parti√ß√µes automaticamente
* Outro consumer assume

> Isso √© **self-healing**, sem interven√ß√£o humana.

---

# 2Ô∏è‚É£ Como funciona internamente (mecanismo real)

### Componentes envolvidos:

| Componente               | Fun√ß√£o                              |
| ------------------------ | ----------------------------------- |
| **Group Coordinator**    | Broker Kafka respons√°vel pelo grupo |
| **Heartbeat**            | Sinal peri√≥dico de vida do consumer |
| **Partition Assignment** | Algoritmo de distribui√ß√£o           |
| **Offsets**              | Posi√ß√£o de leitura por parti√ß√£o     |

---

## üîÑ Ciclo de vida de um Consumer Group

1. Consumer inicia
2. Envia `JoinGroup`
3. Recebe parti√ß√µes
4. Come√ßa a consumir
5. Envia heartbeats
6. Commit de offsets
7. Continua at√© morrer ou escalar

---

## ‚ö†Ô∏è Rebalance (ponto cr√≠tico)

Rebalance ocorre quando:

* Nova EC2 sobe
* EC2 cai
* Parti√ß√µes aumentam
* Consumer fica lento

Durante o rebalance:

* Consumo **pausa**
* Parti√ß√µes s√£o redistribu√≠das
* Offsets s√£o reatribu√≠dos

> ‚ö†Ô∏è Quanto mais parti√ß√µes e mais consumers, mais caro o rebalance.

---

# 3Ô∏è‚É£ Por que sua aplica√ß√£o PRECISA definir um Consumer Group

Na sua arquitetura:

* EC2 Consumer √© **stateless**
* Lambda recebe batches
* Kafka mant√©m estado (offsets)

üëâ **O estado n√£o est√° na aplica√ß√£o, est√° no Kafka**

### Isso permite:

* Escalar EC2 sem reconfigura√ß√£o
* Substituir inst√¢ncias sem perda
* Deploy seguro (rolling update)

---

## üîê group.id = contrato operacional

O `group.id` define:

* Quem divide carga
* Quem compete pelas mensagens
* Quem mant√©m offset

> Se mudar o `group.id`, Kafka entende como **aplica√ß√£o nova**

---

# 4Ô∏è‚É£ Consumer Group no contexto .NET + MSK

### Configura√ß√£o t√≠pica (.NET)

```csharp
var config = new ConsumerConfig
{
    BootstrapServers = "...",
    GroupId = "mt-c400-consumer-group",
    EnableAutoCommit = false,
    AutoOffsetReset = AutoOffsetReset.Earliest,
    MaxPollIntervalMs = 300000,
    SessionTimeoutMs = 45000
};
```

### O que isso significa arquiteturalmente

| Config                   | Impacto                            |
| ------------------------ | ---------------------------------- |
| `GroupId`                | Define cluster l√≥gico de consumers |
| `EnableAutoCommit=false` | Controle transacional              |
| `MaxPollIntervalMs`      | Protege contra consumer lento      |
| `SessionTimeoutMs`       | Define sensibilidade a falhas      |

---

# 5Ô∏è‚É£ Consumer Group ‚â† T√≥pico ‚â† Aplica√ß√£o

Essa confus√£o √© comum:

| Conceito           | Significado                      |
| ------------------ | -------------------------------- |
| **T√≥pico**         | Fluxo de dados                   |
| **Consumer Group** | Cluster l√≥gico de leitura        |
| **Consumer**       | Inst√¢ncia f√≠sica                 |
| **Aplica√ß√£o**      | C√≥digo que implementa o consumer |

---

# 6Ô∏è‚É£ Diagrama Mermaid ‚Äî Consumer Group em detalhes

```mermaid
flowchart LR
    subgraph Kafka["Amazon MSK (Kafka)"]
        T["T√≥pico: mt-c400"]
        P0["Parti√ß√£o 0"]
        P1["Parti√ß√£o 1"]
        P2["Parti√ß√£o 2"]
        P3["Parti√ß√£o 3"]

        T --> P0
        T --> P1
        T --> P2
        T --> P3
    end

    subgraph CG["Consumer Group: mt-c400-consumer-group"]
        C1["Consumer EC2 #1"]
        C2["Consumer EC2 #2"]
        C3["Consumer EC2 #3"]
    end

    P0 -->|assign| C1
    P1 -->|assign| C2
    P2 -->|assign| C3
    P3 -->|assign| C1

    C1 -->|heartbeat| Kafka
    C2 -->|heartbeat| Kafka
    C3 -->|heartbeat| Kafka

    C1 -->|commit offset| Kafka
    C2 -->|commit offset| Kafka
    C3 -->|commit offset| Kafka

    subgraph Rebalance["Rebalance Event"]
        SCALE["Scale Out / Failure"]
        REDIST["Reatribui√ß√£o de Parti√ß√µes"]
    end

    SCALE --> REDIST
    REDIST --> CG
```

---

# 7Ô∏è‚É£ Argumento forte para convencer superiores

> O Consumer Group transforma m√∫ltiplas inst√¢ncias EC2 em **um √∫nico consumidor l√≥gico**, com:
>
> * Escalabilidade horizontal
> * Toler√¢ncia a falhas
> * Preserva√ß√£o de ordem
> * Controle de estado centralizado
>
> Sem ele, a arquitetura seria r√≠gida, fr√°gil e cara.

---

# 8Ô∏è‚É£ Riscos e cuidados (pontos que seniors v√£o perguntar)

| Risco               | Mitiga√ß√£o                     |
| ------------------- | ----------------------------- |
| Rebalance frequente | Menos consumers que parti√ß√µes |
| Consumer lento      | Batching + async              |
| Lag alto            | Auto scaling                  |
| Lambda lento        | Backpressure                  |
| Commit incorreto    | Manual commit                 |

---

## ‚úÖ Frase de encerramento para a documenta√ß√£o

> O Consumer Group √© o mecanismo que permite escalar consumo, garantir ordem e tolerar falhas sem adicionar estado ou complexidade ao servi√ßo.

---

## üëø Principal Engineer (abre a reuni√£o)

> **‚ÄúVamos direto ao ponto. Me explique por que essa arquitetura n√£o vai virar um pesadelo operacional em seis meses.‚Äù**

### ‚úÖ Sua resposta (calma, t√©cnica):

> Porque ela se apoia em primitivas maduras do Kafka:
>
> * consumer group para coordena√ß√£o
> * parti√ß√µes como unidade de paralelismo
> * estado externo (offsets)
>
> N√£o criamos l√≥gica distribu√≠da customizada. Delegamos complexidade ao Kafka, que j√° resolve isso h√° anos.

---

## üëø SRE (j√° atacando)

> **‚ÄúRebalance. Toda vez que eu escuto essa palavra, algu√©m est√° escondendo downtime. Quanto tempo seu sistema fica parado?‚Äù**

### ‚úÖ Resposta certa (sem mentir):

> O consumo pausa durante o rebalance, sim.
>
> Mas:
>
> * n√£o perdemos mensagens
> * o backlog √© absorvido pelas parti√ß√µes
> * usamos batch para amortecer
>
> √â um pause controlado, n√£o downtime funcional.

> E evitamos rebalance frequente controlando autoscaling.

---

## üëø SRE (mais agressivo)

> **‚ÄúQuantos rebalances voc√™ espera por dia?‚Äù**

### ‚ùå Resposta errada:

> ‚ÄúDepende‚Ä¶‚Äù

### ‚úÖ Resposta correta:

> Em steady state: zero.
>
> Apenas em:
>
> * deploy
> * falha de inst√¢ncia
> * scaling manual ou automatizado
>
> N√£o √© um evento de runtime normal.

---

## üëø Principal Engineer (olhando o desenho)

> **‚ÄúVoc√™ tem 40 parti√ß√µes e 10 consumers. Por qu√™?‚Äù**

### ‚úÖ Resposta forte:

> Porque parti√ß√µes s√£o capacidade futura.
>
> Consumers s√£o capacidade atual.
>
> Parti√ß√µes a mais:
>
> * reduzem impacto de scaling
> * evitam redistribui√ß√£o estrutural
> * permitem crescimento sem mudan√ßa de MSK

---

## üëø FinOps (entra pesado)

> **‚ÄúVoc√™ est√° criando EC2 s√≥ para chamar Lambda. Isso √© burrice ou luxo?‚Äù**

üòê sil√™ncio na call‚Ä¶

### ‚úÖ Resposta que salva:

> Lambda n√£o √© um bom consumer Kafka com mTLS e controle fino de batch.
>
> EC2:
>
> * controla backpressure
> * controla commit
> * reduz invoca√ß√µes Lambda via batch
>
> No fim, reduz custo total e risco operacional.

---

## üëø FinOps (pressionando)

> **‚ÄúQuanto custa esse batch?‚Äù**

### ‚úÖ Resposta madura:

> Batch √© uma decis√£o econ√¥mica e t√©cnica.
>
> Menos invoca√ß√µes Lambda
> Menos custo por request
> Melhor uso de CPU
>
> O batch √© parametriz√°vel e monitorado via latency e lag.

---

## üëø Principal Engineer (ataque cl√°ssico)

> **‚ÄúPor que n√£o um t√≥pico s√≥? Voc√™s est√£o complicando demais.‚Äù**

### ‚ùå Resposta fraca:

> ‚ÄúPorque √© melhor‚Ä¶‚Äù

### ‚úÖ Resposta correta:

> Um t√≥pico √∫nico mistura dom√≠nios, prioridades e ritmos.
>
> Isso gera:
>
> * vizinho barulhento
> * desperd√≠cio de CPU
> * blast radius alto
>
> Preferimos isolamento l√≥gico para preservar estabilidade.

---

## üëø SRE (cutucando ferida)

> **‚ÄúE se um consumer ficar lento?‚Äù**

### ‚úÖ Resposta certa:

> Kafka para de aceitar heartbeat.
>
> Dispara rebalance.
>
> Outro consumer assume.
>
> Offset s√≥ avan√ßa se o Lambda responder OK.

---

## üëø SRE (quase gritando)

> **‚ÄúE SE O LAMBDA FICAR LENTO?‚Äù**

### ‚úÖ Resposta que demonstra senioridade:

> O consumer aplica backpressure automaticamente.
>
> Lag sobe.
>
> Observabilidade detecta.
>
> Scaling ou mitiga√ß√£o √© acionada.
>
> Nenhuma mensagem √© perdida.

---

## üëø Principal Engineer (olhar mortal)

> **‚ÄúO que quebra quando voc√™ aumenta parti√ß√µes?‚Äù**

### ‚úÖ Resposta honesta (n√£o tente esconder):

> A ordena√ß√£o por chave √© afetada.
>
> Por isso:
>
> * fazemos isso de forma controlada
> * temos playbook
> * s√≥ aumentamos quando o ganho supera esse impacto
>
> √â um trade-off consciente.

---

## üëø Principal Engineer (final)

> **‚ÄúQual √© o maior risco dessa arquitetura?‚Äù**

### ‚ùå Resposta errada:

> ‚ÄúN√£o tem.‚Äù

### ‚úÖ Resposta correta:

> Rebalance excessivo e downstream imprevis√≠vel.
>
> Ambos s√£o mitigados com:
>
> * observabilidade
> * batch
> * controle de scaling
>
> S√£o riscos conhecidos, n√£o surpresas.

---

## üëø Pergunta final (sil√™ncio total)

> **‚ÄúSe isso der errado, quem vai acordar √†s 3 da manh√£?‚Äù**

### ‚úÖ Resposta de quem passa:

> A arquitetura foi pensada para que falhas sejam eventos normais e observ√°veis.
>
> O sistema degrada com lag, n√£o com perda.
>
> Se algu√©m acordar √†s 3 da manh√£, ser√° para escalar, n√£o para apagar inc√™ndio.

---

# üèÅ Resultado da reuni√£o

üëâ **Aprovado com ressalvas**
üëâ Pedido de:

* m√©tricas claras de lag
* limites de batch
* playbook de rebalance
* simula√ß√£o em POC

---

## üéØ Dica final (importante)

Em review hostil, **n√£o tente vender perfei√ß√£o**.
Venda:

* trade-offs conscientes
* riscos conhecidos
* mecanismos de mitiga√ß√£o

Isso √© o que diferencia **arquiteto experiente** de ‚Äúdesenhista de diagrama‚Äù.

---

# üìÑ POST-MORTEM T√âCNICO

**Incidente:** Aumento de Lag e Atraso no Processamento
**Sistema:** MSK + Consumer Group (.NET EC2) + Lambda
**Severidade:** SEV-2
**Dura√ß√£o:** 47 minutos
**Impacto:** Atraso no processamento downstream (sem perda de dados)

---

## 1Ô∏è‚É£ Resumo Executivo

Entre **10:13 e 11:00**, o sistema apresentou um aumento significativo de **consumer lag** no t√≥pico `mt-c400`, atingindo um pico de **~1,2 milh√£o de mensagens pendentes**.

Nenhuma mensagem foi perdida.
O sistema se recuperou automaticamente ap√≥s mitiga√ß√£o operacional.

O incidente exp√¥s **limita√ß√µes conhecidas da arquitetura**, que estavam documentadas como trade-offs aceit√°veis.

---

## 2Ô∏è‚É£ Linha do Tempo (Timeline)

| Hor√°rio | Evento                               |
| ------- | ------------------------------------ |
| 10:13   | Deploy de nova vers√£o do consumer    |
| 10:14   | In√≠cio de rebalance                  |
| 10:15   | Lambda come√ßa a responder mais lento |
| 10:18   | Lag cresce rapidamente               |
| 10:25   | Alerta de lag > threshold            |
| 10:30   | Autoscaling acionado                 |
| 10:42   | Rebalance completo                   |
| 11:00   | Lag normalizado                      |

---

## 3Ô∏è‚É£ Impacto ao Neg√≥cio

* ‚ùå **Nenhuma perda de dados**
* ‚ö†Ô∏è Atraso de at√© **8 minutos** no processamento downstream
* ‚úÖ Eventos cr√≠ticos continuaram sendo ingeridos
* ‚ùå SLA de lat√™ncia temporariamente violado

---

## 4Ô∏è‚É£ O que aconteceu (An√°lise T√©cnica Profunda)

### üîπ 4.1 Rebalance em cascata

Durante o deploy:

* 3 inst√¢ncias EC2 foram reiniciadas
* Kafka detectou perda de heartbeat
* Rebalance foi disparado

‚ö†Ô∏è **Importante:**
O rebalance pausou temporariamente o consumo **por design**.

---

### üîπ 4.2 Lambda como gargalo downstream

Durante o rebalance:

* Batch acumulou mensagens
* Lambda come√ßou a responder mais lentamente
* Tempo m√©dio de resposta subiu de 120ms ‚Üí 950ms

Isso causou:

* Atraso no commit de offsets
* Lag crescente

---

### üîπ 4.3 Por que o sistema n√£o quebrou?

Porque:

* Commit era manual
* Offsets n√£o avan√ßaram incorretamente
* Kafka reteve mensagens
* Consumer Group garantiu reassignment correto

üëâ **At-least-once garantido**

---

## 5Ô∏è‚É£ O que N√ÉO aconteceu (mitos comuns)

| Medo comum                        | O que realmente aconteceu                |
| --------------------------------- | ---------------------------------------- |
| ‚ÄúPerdemos mensagens‚Äù              | ‚ùå Kafka reteve tudo                      |
| ‚ÄúConsumers processaram duplicado‚Äù | ‚ö†Ô∏è Pequena duplica√ß√£o aceit√°vel          |
| ‚ÄúSistema caiu‚Äù                    | ‚ùå Sistema degradou                       |
| ‚ÄúPrecisamos refatorar tudo‚Äù       | ‚ùå Arquitetura se comportou como esperado |

---

## 6Ô∏è‚É£ Root Cause (Causa Raiz)

> **Causa prim√°ria:**
> Rebalance simult√¢neo + aumento inesperado de lat√™ncia do Lambda.

> **Causa secund√°ria:**
> Deploy sem estrat√©gia de rolling update com limita√ß√£o de inst√¢ncias simult√¢neas.

---

## 7Ô∏è‚É£ Decis√µes Arquiteturais que se provaram corretas

### ‚úÖ Consumer Group

* Redistribui√ß√£o autom√°tica
* Nenhuma interven√ß√£o manual
* Recupera√ß√£o autom√°tica

### ‚úÖ Batch controlado

* Reduziu custo Lambda
* Amorteceu pico de lag

### ‚úÖ Commit manual

* Nenhuma perda
* Nenhum offset corrompido

---

## 8Ô∏è‚É£ Trade-offs que se manifestaram (e eram conhecidos)

### ‚ö†Ô∏è Rebalance pausa consumo

* Documentado
* Esperado
* Impacto tempor√°rio

### ‚ö†Ô∏è Depend√™ncia de downstream

* Lambda lento impacta lag
* Mitigado por backpressure

---

## 9Ô∏è‚É£ O que poderia ter sido pior (e n√£o foi)

* ‚ùå Commit autom√°tico ‚Üí perda de mensagens
* ‚ùå Lambda direto no MSK ‚Üí falhas imprevis√≠veis
* ‚ùå Estado no consumer ‚Üí recupera√ß√£o manual

---

## 10Ô∏è‚É£ A√ß√µes Corretivas (Action Items)

### üõ†Ô∏è Curto Prazo

* Limitar deploy a 1 EC2 por vez
* Aumentar timeout do Lambda
* Ajustar batch size din√¢mico

### üõ†Ô∏è M√©dio Prazo

* Separar t√≥picos por prioridade
* Criar Lambda dedicado para eventos cr√≠ticos
* Ajustar autoscaling por lag

### üõ†Ô∏è Longo Prazo

* Consumer dedicado para high-priority
* Circuit breaker no downstream
* Teste de caos (rebalance for√ßado)

---

## 11Ô∏è‚É£ Li√ß√µes Aprendidas (o ponto mais importante)

> A arquitetura **n√£o falhou**.
> Ela **degradou de forma previs√≠vel**.

Isso √© exatamente o comportamento esperado em sistemas distribu√≠dos maduros.

---

## 12Ô∏è‚É£ Perguntas dif√≠ceis que surgiram no post-mortem

### ‚ùì ‚ÄúIsso vai acontecer de novo?‚Äù

> Sim. Rebalances s√£o inevit√°veis.

### ‚ùì ‚ÄúPodemos evitar totalmente?‚Äù

> N√£o, mas podemos **reduzir frequ√™ncia e impacto**.

### ‚ùì ‚ÄúVale a pena essa complexidade?‚Äù

> Sim, porque o custo de n√£o t√™-la √© perda de dados ou indisponibilidade total.

---

## 13Ô∏è‚É£ Diagrama Mermaid ‚Äî Incidente e Recupera√ß√£o

```mermaid
sequenceDiagram
    participant EC2 as Consumer EC2
    participant Kafka as MSK
    participant Lambda as Lambda
    participant SRE as SRE

    EC2->>Kafka: Poll()
    Kafka-->>EC2: Mensagens
    EC2->>Lambda: Invoke(batch)
    Lambda-->>EC2: Lat√™ncia ‚Üë
    EC2--xKafka: Commit atrasado
    Kafka->>Kafka: Lag cresce
    SRE->>EC2: Escala consumidores
    Kafka->>EC2: Rebalance
    EC2->>Kafka: Consumo retomado
    EC2->>Lambda: Processamento normal
```

---

## 14Ô∏è‚É£ Frase final para fechar o post-mortem

> Em sistemas distribu√≠dos, falha n√£o √© exce√ß√£o ‚Äî √© estado transit√≥rio.
> O sucesso est√° em **detectar, absorver e recuperar**, n√£o em fingir que n√£o vai acontecer.

Perfeito.
Abaixo est√° **uma explica√ß√£o EXTREMAMENTE detalhada**, acompanhada de **diagramas Mermaid grandes**, cobrindo **exatamente o que voc√™ tem que fazer**, **como**, **por qu√™** e **como tudo se conecta**, respeitando **todas as restri√ß√µes**:

* MSK em **outra conta**
* Sem acesso administrativo ao cluster
* Apenas **cria√ß√£o/configura√ß√£o de t√≥picos**
* Producer e Consumer em **EC2 (.NET)**
* Consumer chamando **Lambda distribuidor**
* Uso expl√≠cito de **t√≥picos, parti√ß√µes e consumer group**

Vou dividir em **4 blocos grandes** para facilitar documenta√ß√£o e defesa arquitetural.

---

# üß± VIS√ÉO GERAL DA ARQUITETURA (O TODO)

Antes de entrar em Producer/Consumer, √© essencial **fixar o modelo mental correto**:

> **Kafka (MSK) √© o sistema de coordena√ß√£o e estado**
> Producer e Consumer s√£o **stateless**
> Consumer Group √© o **mecanismo de escala e resili√™ncia**

---

## üìå Arquitetura l√≥gica (alto n√≠vel)

```mermaid
flowchart LR
    subgraph AccountA["Conta A - Infra Kafka"]
        MSK["Amazon MSK<br/>(Kafka Cluster)"]
        T1["T√≥pico mt-c400<br/>(20+ Parti√ß√µes)"]
        T2["T√≥pico mt-c300<br/>(8+ Parti√ß√µes)"]
        MSK --> T1
        MSK --> T2
    end

    subgraph AccountB["Conta B - Aplica√ß√µes"]
        P["Producer .NET<br/>(EC2)"]
        C["Consumer .NET<br/>(EC2)"]
        L["Lambda<br/>Distribuidor"]
    end

    P -->|Produce| MSK
    MSK -->|Consume| C
    C -->|Batch| L
```

---

# üß© BLOCO 1 ‚Äî MODELAGEM DE T√ìPICOS E PARTI√á√ïES (DECIS√ÉO CHAVE)

## üéØ Objetivo

* Permitir **13k msg/s**
* Isolar dom√≠nios
* Minimizar rebalance
* Preparar crescimento

---

## üîπ Estrutura proposta de t√≥picos

| T√≥pico    | Fun√ß√£o                    | Parti√ß√µes | Observa√ß√£o         |
| --------- | ------------------------- | --------- | ------------------ |
| `mt-c400` | Dom√≠nio mais quente (80%) | 20‚Äì40     | Alta paraleliza√ß√£o |
| `mt-c300` | Dom√≠nio m√©dio             | 8‚Äì12      | Menor volume       |
| Outros    | Espec√≠ficos               | conforme  | Isolamento         |

> ‚ö†Ô∏è Importante:
> **C√≥digos N√ÉO viram t√≥picos**, eles viram **chaves de particionamento**

---

## üîπ Regra de ouro

> **T√≥picos = contratos**
> **Parti√ß√µes = paralelismo**
> **Chave = ordem**

---

# üß± BLOCO 2 ‚Äî PRODUCER .NET (EC2)

## üéØ Papel do Producer

* Receber mensagens de v√°rias fontes
* Decidir:

  * **Qual t√≥pico**
  * **Qual chave**
* Nunca decidir consumer, parti√ß√£o manual ou offset

---

## üîÅ Fluxo completo do Producer

```mermaid
flowchart TD
    START["Start Producer Service"]
    LOADCFG["Load Config<br/>(T√≥picos, Brokers, TLS)"]
    TLS["Load Certificado<br/>(mTLS via S3)"]
    INIT["Init Kafka Producer<br/>(.NET)"]

    LOOP["Loop de Produ√ß√£o"]
    BUILD["Build Mensagem JSON"]
    SELECT["Selecionar T√≥pico<br/>(mt-c400 / mt-c300)"]
    KEY["Definir Message Key<br/>(c√≥digo / deviceId)"]
    SEND["ProduceAsync()"]
    ACK{"ACK OK?"}
    RETRY["Retry / DLQ"]
    METRIC["Emitir M√©tricas"]

    START --> LOADCFG --> TLS --> INIT --> LOOP
    LOOP --> BUILD --> SELECT --> KEY --> SEND --> ACK
    ACK -- Sim --> METRIC --> LOOP
    ACK -- N√£o --> RETRY --> LOOP
```

---

## üîπ Como o Producer decide parti√ß√£o (conceito cr√≠tico)

### ‚ùå O que N√ÉO fazer

* N√£o escolher parti√ß√£o manualmente
* N√£o tentar ‚Äúbalancear na m√£o‚Äù
* N√£o criar l√≥gica distribu√≠da customizada

### ‚úÖ O que fazer

* **Definir a `Message.Key`**
* Kafka decide a parti√ß√£o via **hash da key**

```csharp
var message = new Message<string, string>
{
    Key = codigoOuDeviceId,
    Value = json
};

await producer.ProduceAsync("mt-c400", message);
```

---

## üîπ Por que isso √© correto?

* Garante ordem por chave
* Permite aumento de parti√ß√µes
* Mant√©m producer simples
* Evita depend√™ncia do MSK

---

## ‚ö†Ô∏è Pontos perigosos no Producer

| Risco               | Mitiga√ß√£o                      |
| ------------------- | ------------------------------ |
| Hot partition       | Escolher chave bem distribu√≠da |
| Burst de produ√ß√£o   | Buffer interno do Kafka        |
| Falha de broker     | ACK + retry                    |
| Certificado vencido | Rota√ß√£o via S3                 |

---

# üß± BLOCO 3 ‚Äî CONSUMER .NET + CONSUMER GROUP

## üéØ Papel do Consumer

* Ler em paralelo
* Preservar ordem por parti√ß√£o
* Batching
* Chamar Lambda
* Commit manual

---

## üîπ Consumer Group como unidade l√≥gica

```mermaid
flowchart LR
    subgraph Kafka["MSK"]
        T["T√≥pico mt-c400"]
        P0["P0"]
        P1["P1"]
        P2["P2"]
        P3["P3"]
        T --> P0 --> P1 --> P2 --> P3
    end

    subgraph CG["Consumer Group: mt-c400-group"]
        C1["EC2 Consumer #1"]
        C2["EC2 Consumer #2"]
        C3["EC2 Consumer #3"]
    end

    P0 --> C1
    P1 --> C2
    P2 --> C3
    P3 --> C1
```

> Kafka garante:
> **1 parti√ß√£o ‚Üí 1 consumer ativo**

---

## üîÅ Fluxo interno do Consumer

```mermaid
flowchart TD
    START["Start Consumer"]
    LOADCFG["Load group.id"]
    TLS["Load mTLS Cert"]
    SUB["Subscribe Topics"]
    POLL["Poll()"]
    BUFFER["Buffer Mensagens"]
    CHECK{"Batch<br/>ou Timeout?"}
    CALL["Invoke Lambda"]
    COMMIT["Commit Offset"]
    ERROR["Retry / Backoff"]

    START --> LOADCFG --> TLS --> SUB --> POLL
    POLL --> BUFFER --> CHECK
    CHECK -- N√£o --> POLL
    CHECK -- Sim --> CALL
    CALL -- OK --> COMMIT --> POLL
    CALL -- Fail --> ERROR --> POLL
```

---

## üîπ Por que usar Consumer Group

* Escala horizontal autom√°tica
* Rebalance em falha
* Estado fora da aplica√ß√£o
* Deploy seguro

---

# üß± BLOCO 4 ‚Äî LAMBDA DISTRIBUIDOR

## üéØ Papel do Lambda

* N√ÉO consumir Kafka
* N√ÉO manter estado
* Apenas:

  * Roteamento
  * Fan-out
  * Enriquecimento

---

```mermaid
flowchart LR
    C["Consumer EC2"]
    L["Lambda Distribuidor"]
    S1["Servi√ßo A"]
    S2["Servi√ßo B"]
    S3["Servi√ßo C"]

    C -->|Batch JSON| L
    L --> S1
    L --> S2
    L --> S3
```

---

## ‚ö†Ô∏è Trade-off consciente

* Lambda lento ‚Üí lag sobe
* Nenhuma perda
* Backpressure natural

---

# üß† AMARRA√á√ÉO FINAL (PARA DOCUMENTA√á√ÉO)

## O que essa arquitetura FAZ bem

* Escala horizontal
* Tolera falhas
* Isola responsabilidades
* Permite crescimento sem refatora√ß√£o

## O que ela N√ÉO tenta fazer

* Ordem global
* Lat√™ncia zero
* Processamento s√≠ncrono fim-a-fim

---

## üìå Frase de ouro para fechar

> O Kafka √© o c√©rebro do sistema.
> Producer injeta eventos.
> Consumer Group processa em paralelo.
> Lambda distribui.
>
> Nenhuma pe√ßa sabe demais sobre a outra.

---
Perfeito. Abaixo est√° **um diagrama Mermaid √∫nico, grande e did√°tico**, focado **exatamente no que deve ser desenvolvido**, deixando **claras as responsabilidades do Producer, MSK (outra conta), Consumer Group, EC2 e Lambda**.

üëâ **Esse diagrama √© para alinhar time, arquitetura e implementa√ß√£o**
üëâ **N√£o √© conceitual ‚Äî √© operacional**

---

## üìê Diagrama Mermaid ‚Äì Arquitetura Exata a Ser Desenvolvida

```mermaid
flowchart LR
    %% ======================
    %% PRODUCER
    %% ======================
    subgraph PROD["Producer Application (.NET)"]
        A1[Evento de Neg√≥cio\n(ex: Telemetria, Status, Alerta)]
        A2[Define T√≥pico\n(mt-c400, mt-c300, ...)]
        A3[Define Message Key\n(ex: truckId, deviceId)]
        A4[Serializa Payload\n(JSON / Avro)]
        A5[Producer Kafka (.NET)\nacks=all\nidempotent=true]
    end

    %% ======================
    %% MSK OUTRA CONTA
    %% ======================
    subgraph MSK["Amazon MSK (Outra Conta AWS)"]
        direction TB
        T1[T√≥pico mt-c400]
        
        P1[Parti√ß√£o 0]
        P2[Parti√ß√£o 1]
        P3[Parti√ß√£o 2]
        Pn[Parti√ß√£o N]

        T1 --> P1
        T1 --> P2
        T1 --> P3
        T1 --> Pn
    end

    %% ======================
    %% CONSUMER GROUP
    %% ======================
    subgraph CG["Consumer Group: cg-dispatcher"]
        direction TB
        C1[Consumer 1\nEC2]
        C2[Consumer 2\nEC2]
        C3[Consumer 3\nEC2]
    end

    %% ======================
    %% LAMBDA
    %% ======================
    subgraph L["AWS Lambda\nMessage Dispatcher"]
        L1[Valida√ß√£o]
        L2[Transforma√ß√£o]
        L3[Roteamento por Tipo]
    end

    %% ======================
    %% FLUXOS
    %% ======================
    A1 --> A2
    A2 --> A3
    A3 --> A4
    A4 --> A5

    A5 -->|TLS + Auth| T1

    P1 -->|Assigned by Kafka| C1
    P2 -->|Assigned by Kafka| C2
    P3 -->|Assigned by Kafka| C3
    Pn -->|Rebalance| C1

    C1 -->|Invoke| L
    C2 -->|Invoke| L
    C3 -->|Invoke| L

    %% ======================
    %% OBSERVA√á√ïES
    %% ======================
    classDef producer fill:#e3f2fd,stroke:#1e88e5
    classDef kafka fill:#fff3e0,stroke:#fb8c00
    classDef consumer fill:#e8f5e9,stroke:#43a047
    classDef lambda fill:#f3e5f5,stroke:#8e24aa

    class A1,A2,A3,A4,A5 producer
    class T1,P1,P2,P3,Pn kafka
    class C1,C2,C3 consumer
    class L1,L2,L3 lambda
```

---

## üß≠ COMO EXPLICAR ESSE DIAGRAMA PARA O TIME

### 1Ô∏è‚É£ Producer (Responsabilidade Total do Time Externo)

Eles **devem implementar SOMENTE isso**:

* Escolher o **t√≥pico**
* Definir a **key corretamente**
* Enviar mensagem confi√°vel

üëâ **Eles N√ÉO sabem:**

* Quantas parti√ß√µes existem
* Quantos consumers existem
* Como a mensagem ser√° processada

---

### 2Ô∏è‚É£ MSK (Outra Conta ‚Äì Limite de Atua√ß√£o)

* Voc√™s **n√£o gerenciam brokers**
* Voc√™s **n√£o gerenciam consumer**
* S√≥:

  * criam t√≥picos
  * definem parti√ß√µes
  * definem ACLs

---

### 3Ô∏è‚É£ Consumer Group (Seu Dom√≠nio)

* Kafka decide:

  * qual consumer l√™ qual parti√ß√£o
  * quando rebalancear
* Consumers:

  * rodam em EC2
  * pertencem ao **mesmo group.id**

üëâ **Escala = subir EC2**
üëâ **Paralelismo = n√∫mero de parti√ß√µes**

---

### 4Ô∏è‚É£ Lambda (Fan-out / Distribui√ß√£o)

* Consumer:

  * l√™
  * confirma offset
  * chama Lambda
* Lambda:

  * distribui
  * transforma
  * roteia

üëâ Lambda **n√£o l√™ Kafka**
üëâ Kafka **n√£o conhece Lambda**

---

## üîë MENSAGEM-CHAVE PARA O TIME

> O Producer escreve eventos ordenados por key.
> O Kafka distribui.
> O Consumer Group escala.
> A Lambda processa.

---

# üéØ OBJETIVO DO PRODUCER

> Publicar **13.000 msg/s**, JSON (~200 bytes), com:

* **Alta disponibilidade**
* **Entrega confi√°vel**
* **Baixa lat√™ncia**
* **Toler√¢ncia a falhas de rede, broker e rebalanceamento**

Sem depender de acesso administrativo ao MSK.

---

# 1Ô∏è‚É£ TIPOS DE FALHAS QUE VOC√ä PRECISA ASSUMIR QUE V√ÉO ACONTECER

Antes de solu√ß√µes, **o que pode quebrar**:

## üî¥ Falhas no Broker

* Broker reinicia (patch, failover)
* Leader de parti√ß√£o muda
* ISR encolhe temporariamente
* Throttling de I/O

‚û° Kafka **continua funcionando**, mas:

* requests falham
* lat√™ncia aumenta
* metadata fica inv√°lida

---

## üî¥ Falhas de Rede

* Lat√™ncia intermitente (VPC, NACL, SG)
* Packet loss
* Timeout TLS
* PrivateLink inst√°vel

‚û° Sintomas:

* `RequestTimedOut`
* `NotLeaderOrFollower`
* `BrokerNotAvailable`

---

## üî¥ Falhas no Pr√≥prio Producer

* GC pressionado
* Buffer cheio
* Backpressure
* Thread pool saturado

‚û° Sintomas:

* mensagens acumulando
* `Local: Queue full`
* aumento de lat√™ncia

---

## üî¥ Falhas de Autentica√ß√£o / TLS

* Certificado expirado
* Erro de truststore
* Falha no handshake mTLS

‚û° Producer **n√£o consegue conectar**

---

# 2Ô∏è‚É£ PRINC√çPIOS DE ROBUSTEZ (ESSENCIAIS)

Esses princ√≠pios **n√£o s√£o opcionais**:

| Princ√≠pio         | Por qu√™             |
| ----------------- | ------------------- |
| Idempot√™ncia      | Evitar duplicatas   |
| Retry controlado  | Falhas transit√≥rias |
| Timeout expl√≠cito | Evitar deadlock     |
| Backpressure      | Proteger mem√≥ria    |
| Observabilidade   | Saber que quebrou   |
| Shutdown gracioso | Evitar perda        |

---

# 3Ô∏è‚É£ CONFIGURA√á√ïES CR√çTICAS DO PRODUCER (.NET)

Usando `Confluent.Kafka`.

## üîπ Configura√ß√µes B√°sicas (Obrigat√≥rias)

```csharp
var config = new ProducerConfig
{
    BootstrapServers = "...",

    SecurityProtocol = SecurityProtocol.Ssl,
    SslKeystoreLocation = "/tmp/client.p12",
    SslKeystorePassword = "",
    SslKeyPassword = "",

    Acks = Acks.All,               // üîê garante escrita em todos os replicas
    EnableIdempotence = true,      // üîê evita duplicatas
    MessageSendMaxRetries = 5,
    RetryBackoffMs = 200,
    LingerMs = 5,
    BatchSize = 64 * 1024,         // batching
};
```

### ‚ùó Por que isso √© cr√≠tico?

| Config             | O que resolve       |
| ------------------ | ------------------- |
| `acks=all`         | Perda silenciosa    |
| `idempotence=true` | Duplica√ß√£o em retry |
| `linger.ms`        | Throughput          |
| `batch.size`       | Menos syscalls      |
| `retry`            | Falhas transit√≥rias |

---

# 4Ô∏è‚É£ TRATAMENTO DE ERROS (N√ÉO OPCIONAL)

## üîπ Erros Retri√°veis (devem ser reprocessados)

| Erro Kafka            | Motivo             |
| --------------------- | ------------------ |
| `RequestTimedOut`     | Lat√™ncia           |
| `NotLeaderOrFollower` | Rebalance          |
| `BrokerNotAvailable`  | Broker reiniciando |

### Estrat√©gia:

* Retry autom√°tico
* Backoff exponencial
* M√©trica de retry

---

## üîπ Erros FATAIS (n√£o adianta retry)

| Erro                   | A√ß√£o          |
| ---------------------- | ------------- |
| `AuthenticationFailed` | Alertar       |
| `SslHandshakeFailed`   | Falha de cert |
| `InvalidConfiguration` | Fail fast     |

---

## üîπ C√≥digo de Tratamento

```csharp
producer.Produce(topic, message, report =>
{
    if (report.Error.IsError)
    {
        if (report.Error.IsFatal)
        {
            // Circuit breaker / alert
        }
        else
        {
            // Retry ou m√©tricas
        }
    }
});
```

---

# 5Ô∏è‚É£ BACKPRESSURE (ESSENCIAL PARA N√ÉO QUEBRAR O SERVI√áO)

Sem isso, seu Producer **morre sob carga**.

## üîπ O problema

* Kafka fica lento
* Producer continua aceitando mensagens
* Mem√≥ria explode

## üîπ Solu√ß√£o

* `QueueBufferingMaxMessages`
* `QueueBufferingMaxKbytes`

```csharp
QueueBufferingMaxMessages = 100_000,
QueueBufferingMaxKbytes = 100_000
```

### Estrat√©gia adicional

* Pausar entrada de mensagens
* Rejeitar requests upstream
* Shed load

---

# 6Ô∏è‚É£ METADATA E REBALANCE (VOC√ä PRECISA SABER)

Quando:

* parti√ß√£o aumenta
* broker cai
* leader muda

‚û° Producer:

* invalida metadata
* refaz lookup
* pode falhar temporariamente

### Por isso:

* Retry + timeout curto
* Logs claros

---

# 7Ô∏è‚É£ CERTIFICADOS (ROBUSTEZ DE SEGURAN√áA)

Voc√™ j√° tem S3 ‚Üí mTLS, mas aten√ß√£o:

## üîπ Problemas comuns

* Cert expira
* Rota√ß√£o n√£o sincronizada
* Producer n√£o recarrega cert

### Estrat√©gia

* Validar validade no startup
* Reload controlado
* Healthcheck falha se cert inv√°lido

---

# 8Ô∏è‚É£ SHUTDOWN GRACIOSO (MUITO ESQUECIDO)

Sem isso:

* mensagens em buffer s√£o perdidas

## üîπ Obrigat√≥rio

```csharp
producer.Flush(TimeSpan.FromSeconds(10));
producer.Dispose();
```

E:

* SIGTERM handling
* timeout m√°ximo

---

# 9Ô∏è‚É£ OBSERVABILIDADE (SEM ISSO VOC√ä N√ÉO DEFENDE A ARQUITETURA)

## M√©tricas obrigat√≥rias

| M√©trica         | Por qu√™       |
| --------------- | ------------- |
| msgs/sec        | Throughput    |
| latency produce | SLA           |
| retries         | Instabilidade |
| errors          | Incidentes    |
| queue size      | Backpressure  |

Confluent exp√µe via:

* StatisticsHandler
* Prometheus

---

# üîü DIAGRAMA ‚Äì ROBUSTEZ DO PRODUCER

```mermaid
flowchart TD
    A[Evento] --> B[Serialize]
    B --> C[Producer Buffer]

    C -->|Batch| D[Kafka Broker]
    D -->|Ack| C

    D -->|Timeout| E[Retry Backoff]
    E --> C

    D -->|Fatal Error| F[Circuit Breaker]
    F --> G[Alert / Stop]

    C -->|Queue Full| H[Backpressure]
    H --> I[Reject / Slow Down]
```

---

# üî• COMO DEFENDER ISSO NUM REVIEW

Se algu√©m perguntar:

> "Por que tanta configura√ß√£o?"

Resposta:

> Porque Kafka **n√£o falha como banco**.
> Ele degrada, reequilibra e se recupera ‚Äî
> e o Producer precisa sobreviver a isso sem perder dados.

---

# üìå RESUMO EXECUTIVO (PARA DOCUMENTA√á√ÉO)

* Producer √© **stateful**
* Falhas s√£o **esperadas**
* Retry sem idempot√™ncia √© **erro grave**
* Backpressure √© **obrigat√≥rio**
* Observabilidade √© **parte da arquitetura**
* Robustez ‚â† lat√™ncia zero

Perfeito ‚Äî agora vamos **subir o n√≠vel para arquitetura de produ√ß√£o real**, no detalhe que **SRE, Arquiteto Chefe e FinOps esperam ver**.

Vou te entregar:

1. **Modelo conceitual de erro / retry / DLQ**
2. **Fluxo detalhado de decis√£o**
3. **O que √© retry v√°lido vs erro definitivo**
4. **Onde o DLQ entra (mesmo para Producer)**
5. **Diagrama Mermaid bem detalhado**
6. **Como defender isso em review**

---

# 1Ô∏è‚É£ CONCEITO-CHAVE: PRODUCER N√ÉO √â ‚ÄúFIRE AND FORGET‚Äù

Em sistemas cr√≠ticos:

> ‚ùå Producer **n√£o pode** simplesmente falhar silenciosamente
> ‚ùå Retry infinito **n√£o √© aceit√°vel**
> ‚ùå Erro n√£o tratado vira **incidente de produ√ß√£o**

Por isso, usamos **3 camadas**:

1. **Retry em mem√≥ria**
2. **Retry persistido**
3. **DLQ (Dead Letter Queue)**

---

# 2Ô∏è‚É£ TIPOS DE ERRO (CLASSIFICA√á√ÉO OBRIGAT√ìRIA)

## üîπ 1. Erros Transientes (RETRY)

| Erro Kafka            | Causa              |
| --------------------- | ------------------ |
| `RequestTimedOut`     | Lat√™ncia           |
| `NotLeaderOrFollower` | Rebalance          |
| `BrokerNotAvailable`  | Broker reiniciando |
| `NetworkException`    | Intermit√™ncia      |

‚û° **Retry com backoff**

---

## üîπ 2. Erros L√≥gicos / Irrecuper√°veis (DLQ)

| Erro                 | Motivo          |
| -------------------- | --------------- |
| JSON inv√°lido        | Bug upstream    |
| Schema incompat√≠vel  | Evolu√ß√£o errada |
| T√≥pico inexistente   | Config          |
| Certificado inv√°lido | Seguran√ßa       |

‚û° **N√£o adianta retry**

---

## üîπ 3. Erros Tempor√°rios de Neg√≥cio (Retry Persistido)

Ex:

* Downstream fora do ar
* Lambda indispon√≠vel
* Rate limit

‚û° Retry com **persist√™ncia**

---

# 3Ô∏è‚É£ ARQUITETURA DE RETRY (BOAS PR√ÅTICAS)

### ‚ùå Anti-pattern

* Retry infinito em mem√≥ria
* Thread bloqueada
* Backpressure global

### ‚úÖ Padr√£o correto

* Retry com limite
* Backoff exponencial
* Persist√™ncia ap√≥s N tentativas

---

# 4Ô∏è‚É£ ONDE ENTRA O DLQ NO PRODUCER?

> ‚ÄúMas Producer precisa de DLQ?‚Äù

**Sim**, quando:

* Mensagem √© inv√°lida
* Schema n√£o bate
* Pol√≠tica impede envio

O DLQ:

* Pode ser outro t√≥pico Kafka
* Pode ser S3
* Pode ser DynamoDB

---

# 5Ô∏è‚É£ FLUXO COMPLETO: ERRO ‚Üí RETRY ‚Üí DLQ

## üîπ Etapas

1. Recebe evento
2. Valida schema
3. Serializa
4. Envia ao Kafka
5. Avalia retorno
6. Retry?
7. Persistir?
8. DLQ?

---

# 6Ô∏è‚É£ DIAGRAMA MERMAID ‚Äì ERRO / RETRY / DLQ (DETALHADO)

```mermaid
flowchart TD
    A[Evento de Entrada] --> B[Valida√ß√£o / Schema]
    
    B -->|Inv√°lido| DLQ[DLQ - T√≥pico / S3]
    B -->|V√°lido| C[Serialize]

    C --> D[Producer Buffer]

    D -->|Send| E[Kafka Broker]

    E -->|Ack OK| F[Sucesso]

    E -->|Erro Transiente| G[Retry em Mem√≥ria]
    G -->|Tentativas < N| D
    G -->|Tentativas >= N| H[Persistir Retry]

    H --> I[Retry Scheduler]
    I --> D

    E -->|Erro Fatal| DLQ

    D -->|Queue Full| J[Backpressure]
    J --> K[Throttle / Reject]

    style DLQ fill:#ffdddd,stroke:#cc0000,stroke-width:2px
```

---

# 7Ô∏è‚É£ BACKOFF (COMO FAZER DIREITO)

### Exemplo:

* Retry 1: 100ms
* Retry 2: 500ms
* Retry 3: 1s
* Retry 4: 5s
* Retry 5: DLQ

‚û° Evita:

* Thundering herd
* Satura√ß√£o do broker

---

# 8Ô∏è‚É£ EXEMPLO DE DECIS√ÉO EM C# (SIMPLIFICADO)

```csharp
try
{
    producer.Produce(topic, msg);
}
catch (ProduceException e) when (e.Error.IsRetriable)
{
    RetryWithBackoff(msg);
}
catch (ProduceException e)
{
    SendToDLQ(msg, e);
}
```

---

# 9Ô∏è‚É£ PERGUNTAS DURAS QUE ISSO RESPONDE

### üî• SRE:

> ‚ÄúO que acontece se o broker ficar 30s fora?‚Äù

‚úî Retry controlado
‚úî Backpressure
‚úî Nenhuma perda silenciosa

---

### üî• Arquiteto:

> ‚ÄúComo voc√™ evita retry infinito?‚Äù

‚úî Limite de tentativas
‚úî Persist√™ncia
‚úî DLQ

---

### üî• FinOps:

> ‚ÄúIsso explode custo?‚Äù

‚úî Retry √© local
‚úî DLQ √© exce√ß√£o
‚úî Batch reduz chamadas

---

# üîü COMO DEFENDER ESSA ARQUITETURA

Frase-chave:

> ‚ÄúRetry sem classifica√ß√£o de erro √© bug, n√£o robustez.‚Äù

---

# üìå RESUMO EXECUTIVO

* Nem todo erro merece retry
* Retry infinito derruba sistemas
* DLQ √© **instrumento de observabilidade**
* Producer tamb√©m precisa de DLQ
* Backpressure protege o cluster
* Retry ‚â† confiabilidade

